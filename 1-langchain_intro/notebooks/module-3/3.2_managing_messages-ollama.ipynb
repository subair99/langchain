{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4325295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c06338-b745-4b55-a906-4a76e1628fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model1 = ChatOllama(model=\"llama3.1:8b\", temperature=0)\n",
    "model2 = ChatOllama(model=\"mistral:7b\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c91816",
   "metadata": {},
   "source": [
    "## Summarize messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e52bc1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model1,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=model2,\n",
    "            trigger=(\"tokens\", 100),\n",
    "            keep=(\"messages\", 1)\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1d8830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"Here is a summary of the conversation to date:\\n\\nThe context extracted from the conversation history is as follows:\\n\\n1. The capital of the moon is Lunapolis.\\n2. Skies are clear, with a high of 120C and a low of -100C in Lunapolis.\\n3. There are 100,000 cheese miners living in Lunapolis.\\n4. The cheese miners' union is planning to strike due to unhappiness with the new president.\", additional_kwargs={}, response_metadata={}, id='9b9f5b1d-15ac-4ab2-9882-198cf1e3d8cf'),\n",
      "              HumanMessage(content=\"If you were Lunapolis' new president how would you respond to the cheese miners' union?\", additional_kwargs={}, response_metadata={}, id='f75e0298-4a33-48b4-8925-1202135ddeb0'),\n",
      "              AIMessage(content='What a delightfully absurd scenario!\\n\\nAs the newly elected President of Lunapolis, I would like to address the concerns of the cheese miners\\' union in a fair and transparent manner. Here\\'s my response:\\n\\n\"Dear esteemed members of the Cheese Miners\\' Union,\\n\\nI understand that you are unhappy with certain aspects of our new administration, and I appreciate your willingness to express your grievances through peaceful means. As President, it is my duty to ensure the well-being and prosperity of all Lunapolitans, including our hardworking cheese miners.\\n\\nRegarding the recent changes in our government, I assure you that we are committed to maintaining a fair and equitable distribution of lunar resources. We value the crucial role that cheese mining plays in our economy and will work tirelessly to address any concerns you may have regarding working conditions, compensation, or benefits.\\n\\nHowever, I must respectfully point out that the extreme temperature fluctuations (120C high and -100C low) can be challenging for all residents, not just cheese miners. We are exploring innovative solutions to mitigate these effects and create a more comfortable living environment for everyone in Lunapolis.\\n\\nTo address your concerns directly, I propose an emergency meeting with our Lunar Council to discuss the following:\\n\\n1. Improved working conditions and safety measures for cheese miners.\\n2. Enhanced compensation packages and benefits for all lunar residents.\\n3. Development of sustainable solutions to stabilize our lunar climate.\\n\\nI invite you to join me in this effort to build a brighter future for Lunapolis. Together, we can create a more prosperous, equitable, and comfortable society for all.\\n\\nThank you for your dedication to the well-being of our community, and I look forward to working with you to resolve these pressing issues.\"\\n\\nHow\\'s that?', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-01-10T22:44:11.233644413Z', 'done': True, 'done_reason': 'stop', 'total_duration': 369310593539, 'load_duration': 218885404952, 'prompt_eval_count': 121, 'prompt_eval_duration': 27703517413, 'eval_count': 345, 'eval_duration': 121250976904, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019baa0f-34c1-7a40-a23d-faa55af3bf99-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 121, 'output_tokens': 345, 'total_tokens': 466})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage\n",
    "from pprint import pprint\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"What is the capital of the moon?\"),\n",
    "        AIMessage(content=\"The capital of the moon is Lunapolis.\"),\n",
    "        HumanMessage(content=\"What is the weather in Lunapolis?\"),\n",
    "        AIMessage(content=\"Skies are clear, with a high of 120C and a low of -100C.\"),\n",
    "        HumanMessage(content=\"How many cheese miners live in Lunapolis?\"),\n",
    "        AIMessage(content=\"There are 100,000 cheese miners living in Lunapolis.\"),\n",
    "        HumanMessage(content=\"Do you think the cheese miners' union will strike?\"),\n",
    "        AIMessage(content=\"Yes, because they are unhappy with the new president.\"),\n",
    "        HumanMessage(content=\"If you were Lunapolis' new president how would you respond to the cheese miners' union?\"),\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e1a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the conversation to date:\n",
      "\n",
      "The context extracted from the conversation history is as follows:\n",
      "\n",
      "1. The capital of the moon is Lunapolis.\n",
      "2. Skies are clear, with a high of 120C and a low of -100C in Lunapolis.\n",
      "3. There are 100,000 cheese miners living in Lunapolis.\n",
      "4. The cheese miners' union is planning to strike due to unhappiness with the new president.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3c6af",
   "metadata": {},
   "source": [
    "## Trim/delete messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def498e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langchain.agents import AgentState\n",
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain.agents.middleware import before_agent\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "@before_agent\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Remove all the tool messages from the state\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    tool_messages = [m for m in messages if isinstance(m, ToolMessage)]\n",
    "    \n",
    "    return {\"messages\": [RemoveMessage(id=m.id) for m in tool_messages]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8103859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model1,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[trim_messages],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7d4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"My device won't turn on. What should I do?\", additional_kwargs={}, response_metadata={}, id='49dd56a1-187a-483e-b358-a434b5a732ff'),\n",
      "              AIMessage(content='Is the device plugged in and turned on?', additional_kwargs={}, response_metadata={}, id='bc1598b2-7b74-45d1-b22e-c536e283dadc', tool_calls=[], invalid_tool_calls=[]),\n",
      "              HumanMessage(content=\"Yes, it's plugged in and turned on.\", additional_kwargs={}, response_metadata={}, id='39e097cf-73c3-49cf-a10e-60ad046ef989'),\n",
      "              AIMessage(content='Is the device showing any lights or indicators?', additional_kwargs={}, response_metadata={}, id='fdec6677-2421-4b34-a12b-b1d38d8adc49', tool_calls=[], invalid_tool_calls=[]),\n",
      "              HumanMessage(content=\"What's the temperature of the device?\", additional_kwargs={}, response_metadata={}, id='47368bb1-1fdb-43cd-a298-0880ba92b9d4'),\n",
      "              AIMessage(content=\"That's a good question! If the device is overheating, it might not turn on properly. Try to check if the device feels excessively hot to the touch. If it does, try letting it cool down for a bit before trying to turn it on again.\\n\\nIf it doesn't feel hot, let's try some other troubleshooting steps:\\n\\n* Check the power cord and make sure it's securely plugged in.\\n* Try pressing the power button for a longer period of time (some devices require a longer press).\\n* If you're using a laptop, try removing the battery and plugging it back in.\\n* If you're using a desktop, try unplugging all peripherals and trying to turn on the device again.\\n\\nIf none of these steps work, we can try some more advanced troubleshooting or consider other possibilities like a hardware issue.\", additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-01-10T22:45:16.634675447Z', 'done': True, 'done_reason': 'stop', 'total_duration': 64099417358, 'load_duration': 1307226457, 'prompt_eval_count': 78, 'prompt_eval_duration': 9064560002, 'eval_count': 167, 'eval_duration': 53271658104, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019baa14-da88-7962-83f9-033784553f21-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 78, 'output_tokens': 167, 'total_tokens': 245})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"My device won't turn on. What should I do?\"),\n",
    "        ToolMessage(content=\"blorp-x7 initiating diagnostic ping…\", tool_call_id=\"1\"),\n",
    "        AIMessage(content=\"Is the device plugged in and turned on?\"),\n",
    "        HumanMessage(content=\"Yes, it's plugged in and turned on.\"),\n",
    "        ToolMessage(content=\"temp=42C voltage=2.9v … greeble complete.\", tool_call_id=\"2\"),\n",
    "        AIMessage(content=\"Is the device showing any lights or indicators?\"),\n",
    "        HumanMessage(content=\"What's the temperature of the device?\")\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a549ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a good question! If the device is overheating, it might not turn on properly. Try to check if the device feels excessively hot to the touch. If it does, try letting it cool down for a bit before trying to turn it on again.\n",
      "\n",
      "If it doesn't feel hot, let's try some other troubleshooting steps:\n",
      "\n",
      "* Check the power cord and make sure it's securely plugged in.\n",
      "* Try pressing the power button for a longer period of time (some devices require a longer press).\n",
      "* If you're using a laptop, try removing the battery and plugging it back in.\n",
      "* If you're using a desktop, try unplugging all peripherals and trying to turn on the device again.\n",
      "\n",
      "If none of these steps work, we can try some more advanced troubleshooting or consider other possibilities like a hardware issue.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daad292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
