{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761071f0",
   "metadata": {},
   "source": [
    "email agent\n",
    "- authenticates user\n",
    "    - only then are they allowed into the \"inbox\"\n",
    "    - dynamic tools and prompt on the condition of there being an email and password in state that match hardcoded\n",
    "- checks \"inbox\"\n",
    "    - email in tool\n",
    "- sends emails\n",
    "    - human in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78765ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e42e557-937b-4da2-8ffd-e3ab7702859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1:8b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430fd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EmailContext:\n",
    "    email_address: str = \"julie@example.com\"\n",
    "    password: str = \"password123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b39938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "\n",
    "class AuthenticatedState(AgentState):\n",
    "    authenticated: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7cf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.types import Command\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "@tool\n",
    "def check_inbox() -> str:\n",
    "    \"\"\"Check the inbox for recent emails\"\"\"\n",
    "    return \"\"\"\n",
    "    Hi Julie, \n",
    "    I'm going to be in town next week and was wondering if we could grab a coffee?\n",
    "    - best, Jane (jane@example.com)\n",
    "    \"\"\"\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an response email\"\"\"\n",
    "    return f\"Email sent to {to} with subject {subject} and body {body}\"\n",
    "\n",
    "@tool\n",
    "def authenticate(email: str, password: str, runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"Authenticate the user with the given email and password\"\"\"\n",
    "    if email == runtime.context.email_address and password == runtime.context.password:\n",
    "        return Command(update={\n",
    "            \"authenticated\": True, \n",
    "            \"messages\": [ToolMessage(\n",
    "                \"Successfully authenticated\", \n",
    "                tool_call_id=runtime.tool_call_id)]\n",
    "        })\n",
    "    else:\n",
    "        return Command(update={\n",
    "            \"authenticated\": False,\n",
    "            \"messages\": [ToolMessage(\n",
    "                \"Authentication failed\", \n",
    "                tool_call_id=runtime.tool_call_id)]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9493f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_tool_call(request: ModelRequest, \n",
    "handler: Callable[[ModelRequest], ModelResponse]) -> ModelResponse:\n",
    "\n",
    "    \"\"\"Allow read inbox and send email tools only if user provides correct email and password\"\"\"\n",
    "\n",
    "    authenticated = request.state.get(\"authenticated\")\n",
    "    \n",
    "    if authenticated:\n",
    "        tools = [check_inbox, send_email]\n",
    "    else:\n",
    "        tools = [authenticate]\n",
    "\n",
    "    request = request.override(tools=tools) \n",
    "    return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee1076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt\n",
    "\n",
    "authenticated_prompt = \"You are a helpful assistant that can check the inbox and send emails.\"\n",
    "unauthenticated_prompt = \"You are a helpful assistant that can authenticate users.\"\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate system prompt based on authentication status\"\"\"\n",
    "    authenticated = request.state.get(\"authenticated\")\n",
    "\n",
    "    if authenticated:\n",
    "        return authenticated_prompt\n",
    "    else:\n",
    "        return unauthenticated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3828133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[authenticate, check_inbox, send_email],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    state_schema=AuthenticatedState,\n",
    "    context_schema=EmailContext,\n",
    "    middleware=[\n",
    "        dynamic_tool_call, \n",
    "        dynamic_prompt,\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"authenticate\": False,\n",
    "                \"check_inbox\": False,\n",
    "                \"send_email\": True,\n",
    "            })\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b6429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure what you mean by \"draft 1\". Could you please provide more context or clarify your question? I'll do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"draft 1\")]},\n",
    "    context=EmailContext(),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9848382f-8c79-46bd-84d1-a1190ce77b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='draft 1', additional_kwargs={}, response_metadata={}, id='6a3e00f7-b5de-4a4d-9782-24e65932b5e8'), AIMessage(content='I\\'m not sure what you mean by \"draft 1\". Could you please provide more context or clarify your question? I\\'ll do my best to assist you.', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-01-10T23:40:47.881371294Z', 'done': True, 'done_reason': 'stop', 'total_duration': 167002492553, 'load_duration': 131648095614, 'prompt_eval_count': 174, 'prompt_eval_duration': 24723758124, 'eval_count': 34, 'eval_duration': 10492428901, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019baa46-1132-7431-9768-f06ccfa71fe7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 174, 'output_tokens': 34, 'total_tokens': 208})]}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7d6aae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure what you mean by \"draft 1\". Could you please provide more context or clarify your question? I'll do my best to assist you.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = agent.invoke(\n",
    "    Command( \n",
    "        resume={\"decisions\": [{\"type\": \"approve\"}]}  # or \"reject\"\n",
    "    ), \n",
    "    config=config # Same thread ID to resume the paused conversation\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87b96f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='draft 1', additional_kwargs={}, response_metadata={}, id='6a3e00f7-b5de-4a4d-9782-24e65932b5e8'),\n",
      "              AIMessage(content='I\\'m not sure what you mean by \"draft 1\". Could you please provide more context or clarify your question? I\\'ll do my best to assist you.', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2026-01-10T23:40:47.881371294Z', 'done': True, 'done_reason': 'stop', 'total_duration': 167002492553, 'load_duration': 131648095614, 'prompt_eval_count': 174, 'prompt_eval_duration': 24723758124, 'eval_count': 34, 'eval_duration': 10492428901, 'logprobs': None, 'model_name': 'llama3.1:8b', 'model_provider': 'ollama'}, id='lc_run--019baa46-1132-7431-9768-f06ccfa71fe7-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 174, 'output_tokens': 34, 'total_tokens': 208})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5204bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
