{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00525f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d01521c-dc94-454c-bf18-d7a7bf478c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13dbd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ColourContext:\n",
    "    favourite_colour: str = \"blue\"\n",
    "    least_favourite_colour: str = \"yellow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03be72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    context_schema=ColourContext  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec82bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    context=ColourContext()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e923d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='57a65bfa-5953-413f-b15d-5170662df651'),\n",
      "              AIMessage(content='I don’t have enough information to know your favorite colour.\\u202fWould you like to tell me what it is, or perhaps give some clues so I can guess?', additional_kwargs={'reasoning_content': 'The user asks \"What is my favourite colour?\" We have no prior context. We cannot infer. We must respond that we don\\'t know. According to policy, we can ask for clarification. So respond politely asking.'}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 77, 'total_tokens': 163, 'completion_time': 0.177920811, 'completion_tokens_details': {'reasoning_tokens': 44}, 'prompt_time': 0.00289269, 'prompt_tokens_details': None, 'queue_time': 0.004881509, 'total_time': 0.180813501}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_49bfac06f1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c52f6-a267-7832-a1ec-44ac7b53c2c0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 77, 'output_tokens': 86, 'total_tokens': 163, 'output_token_details': {'reasoning': 44}})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292e6b89-dc94-4fd8-b17b-fdf4a92681bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don’t have enough information to know your favorite colour. Would you like to tell me what it is, or perhaps give some clues so I can guess?\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24874360",
   "metadata": {},
   "source": [
    "## Accessing Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd261db6-11a2-47dc-99d4-4c07b1fc82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "@tool\n",
    "def get_favourite_colour(config: RunnableConfig) -> str:\n",
    "    \"\"\"Get the favourite colour of the user\"\"\"\n",
    "    # Accessing the context passed via the 'configurable' field\n",
    "    context = config.get(\"configurable\", {}).get(\"context\")\n",
    "    if context:\n",
    "        return context.favourite_colour\n",
    "    return \"I don't know the favourite colour.\"\n",
    "\n",
    "@tool\n",
    "def get_least_favourite_colour(config: RunnableConfig) -> str:\n",
    "    \"\"\"Get the least favourite colour of the user\"\"\"\n",
    "    context = config.get(\"configurable\", {}).get(\"context\")\n",
    "    if context:\n",
    "        return context.least_favourite_colour\n",
    "    return \"I don't know the least favourite colour.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce743296",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_favourite_colour, get_least_favourite_colour],\n",
    "    context_schema=ColourContext\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8039f5bd-31ee-479c-93f1-721457fcd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session_123\",\n",
    "        \"context\": ColourContext(\n",
    "            favourite_colour=\"blue\", \n",
    "            least_favourite_colour=\"yellow\"\n",
    "        )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46b9b0c-67ac-4162-bc66-4523c5a143ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my favourite colour?', additional_kwargs={}, response_metadata={}, id='05f1da7e-d3b2-441f-ba25-488ec0d9bcba'),\n",
      "              AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to answer using the function get_favourite_colour. The user asks \"What is my favourite colour?\" We should call the function.', 'tool_calls': [{'id': 'fc_b769b4a0-3fa5-407e-a818-d6476b6b4cf6', 'function': {'arguments': '{}', 'name': 'get_favourite_colour'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 149, 'total_tokens': 199, 'completion_time': 0.103196941, 'completion_tokens_details': {'reasoning_tokens': 29}, 'prompt_time': 0.005999419, 'prompt_tokens_details': None, 'queue_time': 0.004750651, 'total_time': 0.10919636}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_8634b911ff', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c52f6-a71d-7b13-83ea-005f35fe5ebb-0', tool_calls=[{'name': 'get_favourite_colour', 'args': {}, 'id': 'fc_b769b4a0-3fa5-407e-a818-d6476b6b4cf6', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 149, 'output_tokens': 50, 'total_tokens': 199, 'output_token_details': {'reasoning': 29}}),\n",
      "              ToolMessage(content='blue', name='get_favourite_colour', id='a7292148-fbcf-47d3-944c-4ade7637d316', tool_call_id='fc_b769b4a0-3fa5-407e-a818-d6476b6b4cf6'),\n",
      "              AIMessage(content='Your favourite colour is **blue**.', additional_kwargs={'reasoning_content': 'We have the function get_favourite_colour returning \"blue\". The user asks \"What is my favourite colour?\" So answer: \"Your favourite colour is blue.\"'}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 174, 'total_tokens': 224, 'completion_time': 0.103797448, 'completion_tokens_details': {'reasoning_tokens': 33}, 'prompt_time': 0.006974914, 'prompt_tokens_details': None, 'queue_time': 0.004842805, 'total_time': 0.110772362}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_8634b911ff', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c52f6-a86b-7333-bfa9-df427d8ab287-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 174, 'output_tokens': 50, 'total_tokens': 224, 'output_token_details': {'reasoning': 33}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my favourite colour?\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab7a1f04-5036-4d6b-9a1b-ffa6bdb54591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is my least favourite colour?', additional_kwargs={}, response_metadata={}, id='1b72f326-bc86-45cf-b83a-6bc9ff0e3197'),\n",
      "              AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to answer user\\'s question: \"What is my least favourite colour?\" We have functions to get favourite and least favourite colour. We should call get_least_favourite_colour.', 'tool_calls': [{'id': 'fc_d71c87cc-6c45-4eca-b9da-a8cd5e2a39ca', 'function': {'arguments': '{}', 'name': 'get_least_favourite_colour'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 150, 'total_tokens': 210, 'completion_time': 0.285401824, 'completion_tokens_details': {'reasoning_tokens': 37}, 'prompt_time': 0.006640392, 'prompt_tokens_details': None, 'queue_time': 0.004613313, 'total_time': 0.292042216}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_2804ae6b41', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c52f6-a9de-7703-b489-27736749d9aa-0', tool_calls=[{'name': 'get_least_favourite_colour', 'args': {}, 'id': 'fc_d71c87cc-6c45-4eca-b9da-a8cd5e2a39ca', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 150, 'output_tokens': 60, 'total_tokens': 210, 'output_token_details': {'reasoning': 37}}),\n",
      "              ToolMessage(content='yellow', name='get_least_favourite_colour', id='c1a20270-bc1e-47d2-b128-baea23625892', tool_call_id='fc_d71c87cc-6c45-4eca-b9da-a8cd5e2a39ca'),\n",
      "              AIMessage(content='Your least favourite colour is **yellow**.', additional_kwargs={'reasoning_content': 'We have the user\\'s least favourite colour returned as \"yellow\". The user asks: \"What is my least favourite colour?\" So answer: \"Your least favourite colour is yellow.\"'}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 179, 'total_tokens': 233, 'completion_time': 0.115365497, 'completion_tokens_details': {'reasoning_tokens': 36}, 'prompt_time': 0.006805151, 'prompt_tokens_details': None, 'queue_time': 0.00524622, 'total_time': 0.122170648}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_178e424650', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c52f6-ac11-7c82-85d2-cc9708c26d0a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 179, 'output_tokens': 54, 'total_tokens': 233, 'output_token_details': {'reasoning': 36}})]}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my least favourite colour?\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c4adca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your least favourite colour is **yellow**.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
