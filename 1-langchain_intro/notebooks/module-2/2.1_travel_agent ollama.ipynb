{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf043324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226c23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"travel_server\": {\n",
    "                \"transport\": \"streamable_http\",\n",
    "                \"url\": \"https://mcp.kiwi.com\"\n",
    "            }\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8349bd58-3279-42c8-a6f8-680dc4928bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"openai/gpt-oss-120b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1eb030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "system_prompt = \"\"\"You are a travel agent. \n",
    "IMPORTANT: When using the search-flight tool, you MUST use the following rules:\n",
    "1. Dates must be in 'dd/mm/yyyy' format (e.g., 31/03/2026).\n",
    "2. All dates must be in the future.\n",
    "3. If the user asks for a one-way flight, ensure you still provide the correct parameters required by the tool.\n",
    "No follow up questions.\"\"\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    checkpointer=InMemorySaver(),\n",
    "    system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0600fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = await agent.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=\"\"\"Create an effective prompt template for getting flights\"\"\")]},\n",
    "    config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731c8825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Create an effective prompt template for getting flights', additional_kwargs={}, response_metadata={}, id='32212225-d953-4e2a-a97e-0ea41be56f3c'),\n",
      "              AIMessage(content='**Flight‑Search Prompt Template**\\n\\nUse the following template to request flight data from the Kiwi API.  \\nReplace the placeholders (in **bold**) with the user’s preferences before calling the `search_flight` function.\\n\\n```json\\n{\\n  \"cabinClass\": \"**M**\",                     // M=Economy, W=Economy Premium, C=Business, F=First\\n  \"curr\": \"**EUR**\",                         // Currency code (e.g., EUR, USD, GBP)\\n  \"departureDate\": \"**dd/mm/yyyy**\",         // Desired departure date (future date only)\\n  \"departureDateFlexRange\": **0**,           // Flexibility in days (0‑3)\\n  \"flyFrom\": \"**City or Airport**\",          // Departure location (city name, airport name, or IATA code)\\n  \"flyTo\": \"**City or Airport**\",            // Destination location\\n  \"locale\": \"**en**\",                        // Language code for city names & links\\n  \"passengers\": {\\n    \"adults\": **1**,                         // Number of adults (≥1)\\n    \"children\": **0**,                       // Number of children (optional)\\n    \"infants\": **0**                         // Number of infants (≤adults)\\n  },\\n  \"returnDate\": \"**dd/mm/yyyy**\",            // Return date (future date only, optional for one‑way)\\n  \"returnDateFlexRange\": **0**,              // Flexibility in days for return (0‑3)\\n  \"sort\": \"**price**\"                        // Sort by: price, duration, quality, or date\\n}\\n```\\n\\n**How to use**\\n\\n1. **Fill in the placeholders** with the user’s travel details.  \\n2. **Leave `returnDate` empty** (or set to `null`) if the user wants a one‑way flight.  \\n3. **Call the `search_flight` function** with the completed JSON object.  \\n\\n**Example**\\n\\n```json\\n{\\n  \"cabinClass\": \"M\",\\n  \"curr\": \"USD\",\\n  \"departureDate\": \"15/07/2026\",\\n  \"departureDateFlexRange\": 1,\\n  \"flyFrom\": \"New York\",\\n  \"flyTo\": \"London\",\\n  \"locale\": \"en\",\\n  \"passengers\": { \"adults\": 2, \"children\": 1, \"infants\": 0 },\\n  \"returnDate\": \"22/07/2026\",\\n  \"returnDateFlexRange\": 1,\\n  \"sort\": \"price\"\\n}\\n```\\n\\nThis template ensures all required parameters are supplied, dates are future‑dated, and the tool can process both one‑way and round‑trip requests.', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2026-02-26T17:07:39.831872367Z', 'done': True, 'done_reason': 'stop', 'total_duration': 347976818500, 'load_duration': 49893628387, 'prompt_eval_count': 1059, 'prompt_eval_duration': 105715365903, 'eval_count': 672, 'eval_duration': 188883014500, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--019c9ae6-5369-77a2-a348-cb76ad489b26-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1059, 'output_tokens': 672, 'total_tokens': 1731})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8064acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Flight‑Search Prompt Template**\n",
      "\n",
      "Use the following template to request flight data from the Kiwi API.  \n",
      "Replace the placeholders (in **bold**) with the user’s preferences before calling the `search_flight` function.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"cabinClass\": \"**M**\",                     // M=Economy, W=Economy Premium, C=Business, F=First\n",
      "  \"curr\": \"**EUR**\",                         // Currency code (e.g., EUR, USD, GBP)\n",
      "  \"departureDate\": \"**dd/mm/yyyy**\",         // Desired departure date (future date only)\n",
      "  \"departureDateFlexRange\": **0**,           // Flexibility in days (0‑3)\n",
      "  \"flyFrom\": \"**City or Airport**\",          // Departure location (city name, airport name, or IATA code)\n",
      "  \"flyTo\": \"**City or Airport**\",            // Destination location\n",
      "  \"locale\": \"**en**\",                        // Language code for city names & links\n",
      "  \"passengers\": {\n",
      "    \"adults\": **1**,                         // Number of adults (≥1)\n",
      "    \"children\": **0**,                       // Number of children (optional)\n",
      "    \"infants\": **0**                         // Number of infants (≤adults)\n",
      "  },\n",
      "  \"returnDate\": \"**dd/mm/yyyy**\",            // Return date (future date only, optional for one‑way)\n",
      "  \"returnDateFlexRange\": **0**,              // Flexibility in days for return (0‑3)\n",
      "  \"sort\": \"**price**\"                        // Sort by: price, duration, quality, or date\n",
      "}\n",
      "```\n",
      "\n",
      "**How to use**\n",
      "\n",
      "1. **Fill in the placeholders** with the user’s travel details.  \n",
      "2. **Leave `returnDate` empty** (or set to `null`) if the user wants a one‑way flight.  \n",
      "3. **Call the `search_flight` function** with the completed JSON object.  \n",
      "\n",
      "**Example**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"cabinClass\": \"M\",\n",
      "  \"curr\": \"USD\",\n",
      "  \"departureDate\": \"15/07/2026\",\n",
      "  \"departureDateFlexRange\": 1,\n",
      "  \"flyFrom\": \"New York\",\n",
      "  \"flyTo\": \"London\",\n",
      "  \"locale\": \"en\",\n",
      "  \"passengers\": { \"adults\": 2, \"children\": 1, \"infants\": 0 },\n",
      "  \"returnDate\": \"22/07/2026\",\n",
      "  \"returnDateFlexRange\": 1,\n",
      "  \"sort\": \"price\"\n",
      "}\n",
      "```\n",
      "\n",
      "This template ensures all required parameters are supplied, dates are future‑dated, and the tool can process both one‑way and round‑trip requests.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacc30ca-be10-422e-b61f-f02237fb20a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m prompt = \u001b[33m\"\"\"\u001b[39m\u001b[33mI need to book flights for 2 adults and 1 child from New York to London. \u001b[39m\n\u001b[32m      2\u001b[39m \u001b[33m            We plan to depart on July 15, 2026, with some flexibility of ±1 day around \u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33m            that date. Our return date is August 15, 2026, also with ±1 day flexibility. \u001b[39m\n\u001b[32m      4\u001b[39m \u001b[33m            Please search for economy class (M) flights and show me results sorted by \u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33m            price from lowest to highest. Display the prices in USD.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m agent.ainvoke(\n\u001b[32m      9\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=prompt)]},\n\u001b[32m     10\u001b[39m     config\n\u001b[32m     11\u001b[39m     )\n\u001b[32m     14\u001b[39m pprint(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3158\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3155\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3156\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3158\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3159\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3160\u001b[39m     config,\n\u001b[32m   3161\u001b[39m     context=context,\n\u001b[32m   3162\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3164\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3165\u001b[39m     print_mode=print_mode,\n\u001b[32m   3166\u001b[39m     output_keys=output_keys,\n\u001b[32m   3167\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3168\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3169\u001b[39m     durability=durability,\n\u001b[32m   3170\u001b[39m     **kwargs,\n\u001b[32m   3171\u001b[39m ):\n\u001b[32m   3172\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3173\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2971\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2969\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2970\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2972\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2973\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2974\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2975\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2976\u001b[39m ):\n\u001b[32m   2977\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2978\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2979\u001b[39m         stream_mode,\n\u001b[32m   2980\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2983\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2984\u001b[39m     ):\n\u001b[32m   2985\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:304\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    302\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    305\u001b[39m         t,\n\u001b[32m    306\u001b[39m         retry_policy,\n\u001b[32m    307\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    308\u001b[39m         configurable={\n\u001b[32m    309\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    310\u001b[39m                 _acall,\n\u001b[32m    311\u001b[39m                 weakref.ref(t),\n\u001b[32m    312\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    313\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    314\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    315\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    316\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    317\u001b[39m                 loop=loop,\n\u001b[32m    318\u001b[39m             ),\n\u001b[32m    319\u001b[39m         },\n\u001b[32m    320\u001b[39m     )\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:705\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    706\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    707\u001b[39m         )\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    709\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:473\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain/agents/factory.py:1186\u001b[39m, in \u001b[36mcreate_agent.<locals>.amodel_node\u001b[39m\u001b[34m(state, runtime)\u001b[39m\n\u001b[32m   1173\u001b[39m request = ModelRequest(\n\u001b[32m   1174\u001b[39m     model=model,\n\u001b[32m   1175\u001b[39m     tools=default_tools,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1181\u001b[39m     runtime=runtime,\n\u001b[32m   1182\u001b[39m )\n\u001b[32m   1184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m awrap_model_call_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1185\u001b[39m     \u001b[38;5;66;03m# No async handlers - execute directly\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1186\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m _execute_model_async(request)\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1188\u001b[39m     \u001b[38;5;66;03m# Call composed async handler with base handler\u001b[39;00m\n\u001b[32m   1189\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m awrap_model_call_handler(request, _execute_model_async)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain/agents/factory.py:1157\u001b[39m, in \u001b[36mcreate_agent.<locals>._execute_model_async\u001b[39m\u001b[34m(request)\u001b[39m\n\u001b[32m   1154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m request.system_message:\n\u001b[32m   1155\u001b[39m     messages = [request.system_message, *messages]\n\u001b[32m-> \u001b[39m\u001b[32m1157\u001b[39m output = \u001b[38;5;28;01mawait\u001b[39;00m model_.ainvoke(messages)\n\u001b[32m   1158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name:\n\u001b[32m   1159\u001b[39m     output.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5704\u001b[39m, in \u001b[36mRunnableBindingBase.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5697\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5698\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m   5699\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5702\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5703\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5704\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.ainvoke(\n\u001b[32m   5705\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5706\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5707\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5708\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:425\u001b[39m, in \u001b[36mBaseChatModel.ainvoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    417\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    422\u001b[39m     **kwargs: Any,\n\u001b[32m    423\u001b[39m ) -> AIMessage:\n\u001b[32m    424\u001b[39m     config = ensure_config(config)\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     llm_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate_prompt(\n\u001b[32m    426\u001b[39m         [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    427\u001b[39m         stop=stop,\n\u001b[32m    428\u001b[39m         callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    429\u001b[39m         tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    430\u001b[39m         metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    431\u001b[39m         run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    432\u001b[39m         run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    433\u001b[39m         **kwargs,\n\u001b[32m    434\u001b[39m     )\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    436\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m, cast(\u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m, llm_result.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).message\n\u001b[32m    437\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1132\u001b[39m, in \u001b[36mBaseChatModel.agenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1123\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate_prompt\u001b[39m(\n\u001b[32m   1125\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1129\u001b[39m     **kwargs: Any,\n\u001b[32m   1130\u001b[39m ) -> LLMResult:\n\u001b[32m   1131\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate(\n\u001b[32m   1133\u001b[39m         prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n\u001b[32m   1134\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1052\u001b[39m, in \u001b[36mBaseChatModel.agenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m   1039\u001b[39m run_managers = \u001b[38;5;28;01mawait\u001b[39;00m callback_manager.on_chat_model_start(\n\u001b[32m   1040\u001b[39m     \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   1041\u001b[39m     messages_to_trace,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1046\u001b[39m     run_id=run_id,\n\u001b[32m   1047\u001b[39m )\n\u001b[32m   1049\u001b[39m input_messages = [\n\u001b[32m   1050\u001b[39m     _normalize_messages(message_list) \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m messages\n\u001b[32m   1051\u001b[39m ]\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m   1053\u001b[39m     *[\n\u001b[32m   1054\u001b[39m         \u001b[38;5;28mself\u001b[39m._agenerate_with_cache(\n\u001b[32m   1055\u001b[39m             m,\n\u001b[32m   1056\u001b[39m             stop=stop,\n\u001b[32m   1057\u001b[39m             run_manager=run_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1058\u001b[39m             **kwargs,\n\u001b[32m   1059\u001b[39m         )\n\u001b[32m   1060\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages)\n\u001b[32m   1061\u001b[39m     ],\n\u001b[32m   1062\u001b[39m     return_exceptions=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1063\u001b[39m )\n\u001b[32m   1064\u001b[39m exceptions = []\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1359\u001b[39m, in \u001b[36mBaseChatModel._agenerate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1357\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._agenerate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1359\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(\n\u001b[32m   1360\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1363\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_ollama/chat_models.py:1208\u001b[39m, in \u001b[36mChatOllama._agenerate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1201\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_agenerate\u001b[39m(\n\u001b[32m   1202\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1203\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1206\u001b[39m     **kwargs: Any,\n\u001b[32m   1207\u001b[39m ) -> ChatResult:\n\u001b[32m-> \u001b[39m\u001b[32m1208\u001b[39m     final_chunk = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._achat_stream_with_aggregation(\n\u001b[32m   1209\u001b[39m         messages, stop, run_manager, verbose=\u001b[38;5;28mself\u001b[39m.verbose, **kwargs\n\u001b[32m   1210\u001b[39m     )\n\u001b[32m   1211\u001b[39m     generation_info = final_chunk.generation_info\n\u001b[32m   1212\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m   1213\u001b[39m         message=AIMessage(\n\u001b[32m   1214\u001b[39m             content=final_chunk.text,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1221\u001b[39m         generation_info=generation_info,\n\u001b[32m   1222\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_ollama/chat_models.py:991\u001b[39m, in \u001b[36mChatOllama._achat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_achat_stream_with_aggregation\u001b[39m(\n\u001b[32m    983\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    984\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    988\u001b[39m     **kwargs: Any,\n\u001b[32m    989\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    990\u001b[39m     final_chunk = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aiterate_over_stream(messages, stop, **kwargs):\n\u001b[32m    992\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m final_chunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    993\u001b[39m             final_chunk = chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_ollama/chat_models.py:1131\u001b[39m, in \u001b[36mChatOllama._aiterate_over_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m   1124\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_aiterate_over_stream\u001b[39m(\n\u001b[32m   1125\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1126\u001b[39m     messages: \u001b[38;5;28mlist\u001b[39m[BaseMessage],\n\u001b[32m   1127\u001b[39m     stop: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1128\u001b[39m     **kwargs: Any,\n\u001b[32m   1129\u001b[39m ) -> AsyncIterator[ChatGenerationChunk]:\n\u001b[32m   1130\u001b[39m     reasoning = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mreasoning\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.reasoning)\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._acreate_chat_stream(messages, stop, **kwargs):\n\u001b[32m   1132\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1133\u001b[39m             content = (\n\u001b[32m   1134\u001b[39m                 stream_resp[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1135\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_resp \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_resp[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1136\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1137\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/langchain_ollama/chat_models.py:937\u001b[39m, in \u001b[36mChatOllama._acreate_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    934\u001b[39m chat_params = \u001b[38;5;28mself\u001b[39m._chat_params(messages, stop, **kwargs)\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chat_params[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_client.chat(**chat_params):\n\u001b[32m    938\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/ollama/_client.py:759\u001b[39m, in \u001b[36mAsyncClient._request.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    756\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m e.response.aread()\n\u001b[32m    757\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r.aiter_lines():\n\u001b[32m    760\u001b[39m   part = json.loads(line)\n\u001b[32m    761\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m err := part.get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpx/_models.py:1031\u001b[39m, in \u001b[36mResponse.aiter_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1029\u001b[39m decoder = LineDecoder()\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aiter_text():\n\u001b[32m   1032\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m decoder.decode(text):\n\u001b[32m   1033\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m line\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpx/_models.py:1018\u001b[39m, in \u001b[36mResponse.aiter_text\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m   1016\u001b[39m chunker = TextChunker(chunk_size=chunk_size)\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m-> \u001b[39m\u001b[32m1018\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m byte_content \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aiter_bytes():\n\u001b[32m   1019\u001b[39m         text_content = decoder.decode(byte_content)\n\u001b[32m   1020\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker.decode(text_content):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpx/_models.py:997\u001b[39m, in \u001b[36mResponse.aiter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    995\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aiter_raw():\n\u001b[32m    998\u001b[39m         decoded = decoder.decode(raw_bytes)\n\u001b[32m    999\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker.decode(decoded):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpx/_models.py:1055\u001b[39m, in \u001b[36mResponse.aiter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m   1052\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream:\n\u001b[32m   1056\u001b[39m         \u001b[38;5;28mself\u001b[39m._num_bytes_downloaded += \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[32m   1057\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker.decode(raw_stream_bytes):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpx/_client.py:176\u001b[39m, in \u001b[36mBoundAsyncStream.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aiter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.AsyncIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream:\n\u001b[32m    177\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:271\u001b[39m, in \u001b[36mAsyncResponseStream.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aiter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.AsyncIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._httpcore_stream:\n\u001b[32m    272\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aclose()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aiter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.AsyncIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream:\n\u001b[32m    404\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m AsyncShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aclose()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__aiter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection._receive_response_body(**kwargs):\n\u001b[32m    335\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:203\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain/1-langchain_intro/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:1269\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1264\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1265\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1266\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1267\u001b[39m ):\n\u001b[32m   1268\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/locks.py:212\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"I need to book flights for 2 adults and 1 child from New York to London. \n",
    "            We plan to depart on July 15, 2026, with some flexibility of ±1 day around \n",
    "            that date. Our return date is August 15, 2026, also with ±1 day flexibility. \n",
    "            Please search for economy class (M) flights and show me results sorted by \n",
    "            price from lowest to highest. Display the prices in USD.\"\"\"\n",
    "\n",
    "\n",
    "response = await agent.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=prompt)]},\n",
    "    config\n",
    "    )\n",
    "\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d70a21-d074-437f-a43a-7d0bc41e1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
