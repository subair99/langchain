{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ea7827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b119bc",
   "metadata": {},
   "source": [
    "## No memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b1b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    \"groq:llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f0de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = HumanMessage(content=\"Hello my name is Seán and my favourite colour is green\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7830523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello my name is Seán and my favourite colour is green', additional_kwargs={}, response_metadata={}, id='6e8a0633-f287-4671-8055-acb2051e045a'),\n",
      "              AIMessage(content=\"Hello Seán! It's lovely to meet you. Green is a wonderful colour, so calming and natural. What do you like most about the colour green? Is it the way it reminds you of nature, or perhaps a favourite sports team or hobby that features green?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 47, 'total_tokens': 102, 'completion_time': 0.173357759, 'completion_tokens_details': None, 'prompt_time': 0.002704826, 'prompt_tokens_details': None, 'queue_time': 0.051857757, 'total_time': 0.176062585}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3410-91ca-7481-834e-40c314fd788f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 47, 'output_tokens': 55, 'total_tokens': 102})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfa97b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"What's my favourite colour?\", additional_kwargs={}, response_metadata={}, id='bc95c8f7-ec69-4fb9-b9c7-d8f242f29174'),\n",
      "              AIMessage(content=\"I don't have any information about your personal preferences, including your favourite colour. I'm a large language model, I don't have the ability to recall personal details about individual users. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations. Would you like to tell me about your favourite colour?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 41, 'total_tokens': 113, 'completion_time': 0.173542228, 'completion_tokens_details': None, 'prompt_time': 0.001962515, 'prompt_tokens_details': None, 'queue_time': 0.042376456, 'total_time': 0.175504743}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3410-a136-7691-b9f4-0a82a63e8de6-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 41, 'output_tokens': 72, 'total_tokens': 113})]}\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage(content=\"What's my favourite colour?\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]} \n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ccbb835-bfbf-48a9-84b9-72fa937c12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have any information about your personal preferences, including your favourite colour. I'm a large language model, I don't have the ability to recall personal details about individual users. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations. Would you like to tell me about your favourite colour?\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ab738",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8be0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver  \n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    \"groq:llama-3.3-70b-versatile\",\n",
    "    checkpointer=InMemorySaver(), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4177a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = HumanMessage(content=\"Hello my name is Seán and my favourite colour is green\")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]},\n",
    "    config,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2adc1407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello my name is Seán and my favourite colour is green', additional_kwargs={}, response_metadata={}, id='c7d06fd7-c242-448f-8ab4-9506b31364ba'),\n",
      "              AIMessage(content=\"Hello Seán! It's lovely to meet you. Green is a wonderful colour, isn't it? So calming and natural. Is there something in particular that draws you to the colour green, or is it just a colour that you've always been fond of?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 47, 'total_tokens': 101, 'completion_time': 0.145065519, 'completion_tokens_details': None, 'prompt_time': 0.013063478, 'prompt_tokens_details': None, 'queue_time': 0.050694977, 'total_time': 0.158128997}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3411-cb74-7da2-8dc0-45d225d073fa-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 47, 'output_tokens': 54, 'total_tokens': 101})]}\n"
     ]
    }
   ],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a2b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hello my name is Seán and my favourite colour is green', additional_kwargs={}, response_metadata={}, id='c7d06fd7-c242-448f-8ab4-9506b31364ba'),\n",
      "              AIMessage(content=\"Hello Seán! It's lovely to meet you. Green is a wonderful colour, isn't it? So calming and natural. Is there something in particular that draws you to the colour green, or is it just a colour that you've always been fond of?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 47, 'total_tokens': 101, 'completion_time': 0.145065519, 'completion_tokens_details': None, 'prompt_time': 0.013063478, 'prompt_tokens_details': None, 'queue_time': 0.050694977, 'total_time': 0.158128997}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_f8b414701e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3411-cb74-7da2-8dc0-45d225d073fa-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 47, 'output_tokens': 54, 'total_tokens': 101}),\n",
      "              HumanMessage(content=\"What's my favourite colour?\", additional_kwargs={}, response_metadata={}, id='72be3a7e-ef2e-48c6-a842-95b5d0801207'),\n",
      "              AIMessage(content='I remember! Your favourite colour is green, Seán!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 116, 'total_tokens': 129, 'completion_time': 0.029881171, 'completion_tokens_details': None, 'prompt_time': 0.051184103, 'prompt_tokens_details': None, 'queue_time': 0.176524857, 'total_time': 0.081065274}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c3411-d8b2-71b0-ab7e-6c6d1cf0f3ac-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 116, 'output_tokens': 13, 'total_tokens': 129})]}\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage(content=\"What's my favourite colour?\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]},\n",
    "    config,  \n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cbb64ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I remember! Your favourite colour is green, Seán!\n"
     ]
    }
   ],
   "source": [
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedadee4-a69a-4f78-becd-9d9c6b6efdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
