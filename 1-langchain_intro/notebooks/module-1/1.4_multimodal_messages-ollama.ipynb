{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74a0d45",
   "metadata": {},
   "source": [
    "## Text input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1efef",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d199fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ea1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "model = ChatOllama(model=\"gpt-oss:20b\", temperature=0.8)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a science fiction writer, create a capital city at the users request.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80786a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The capital of the Moon is called *Luna Nova*—the “New Moon City.”**\n",
      "\n",
      "Nestled in the heart of the Mare Tranquillitatis, Luna Nova rises from the regolith as a gleaming lattice of white and silvery titanium. Its concentric rings of habitat modules form a ringed city that orbits the surface like a living, breathing organism. At its core sits the *Heliarch*—a transparent, rotating dome that houses the Lunar Council and the Interplanetary Assembly, where representatives from Earth, Mars, and the asteroid belt convene to govern the Moon’s colonies.\n",
      "\n",
      "Key features of Luna Nova:\n",
      "\n",
      "- **Solar Nexus** – A vast photovoltaic array that powers the entire city, feeding energy into the lunar grid and providing excess power to off‑world missions.\n",
      "- **The Lattice Market** – A bustling marketplace built into the city’s outer rings, where traders exchange Earth‑derived goods, lunar regolith‑based materials, and exotic bio‑engineered food.\n",
      "- **The Lunar Library** – A repository of all human knowledge, stored in micro‑titanium vaults and accessed via quantum‑linked holographic interfaces.\n",
      "- **The Skywalks** – Elevated, gravity‑modulated walkways that let citizens stroll above the regolith, offering panoramic views of the Earthrise and the black expanse of space.\n",
      "\n",
      "Luna Nova is not just a political center; it is a beacon of human ingenuity and the first true “city of the Moon,” where the boundary between science and art blurs beneath the silver glow of the lunar horizon.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"What is the capital of The Moon?\"}\n",
    "])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9205f9",
   "metadata": {},
   "source": [
    "## Image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c6e6e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdab5a5ddad48c796908ac9438aec55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.jpg', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "\n",
    "uploader = FileUpload(accept='.jpg', multiple=False)\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f71141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'name': 'langchain-picture.jpg', 'type': 'image/jpeg', 'size': 46865, 'content': <memory at 0x7c70147d9240>, 'last_modified': datetime.datetime(2026, 2, 6, 18, 13, 50, 575000, tzinfo=datetime.timezone.utc)},)\n"
     ]
    }
   ],
   "source": [
    "print(uploader.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21debb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Get the first (and only) uploaded file dict\n",
    "uploaded_file = uploader.value[0]\n",
    "\n",
    "# This is a memoryview\n",
    "content_mv = uploaded_file[\"content\"]\n",
    "\n",
    "# Convert memoryview -> bytes\n",
    "img_bytes = bytes(content_mv)  # or content_mv.tobytes()\n",
    "\n",
    "# Now base64 encode\n",
    "img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0cac77-1338-43ca-ab59-c0cee0f95116",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"qwen3-vl:8b\", temperature=0.8)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a science fiction writer, create a capital city at the users request.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604afd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Tell me about this capital\"},\n",
    "    {\"type\": \"image\", \"base64\": img_b64, \"mime_type\": \"image/.jpg\"}\n",
    "])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [multimodal_question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e262fb1c",
   "metadata": {},
   "source": [
    "## Audio input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ad1c0-ebc6-44c8-922d-ad6a7ad13c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "\n",
    "uploader = FileUpload(accept='.mp3', multiple=False)\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5097e86-5609-4ce6-baa2-2522429aa802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uploader.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd54df-ec8d-496d-80ed-7ebdff7d6e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from faster_whisper import WhisperModel\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 1. Initialize the Transcription Model (Runs locally)\n",
    "# \"base\" is fast, \"small\" is more accurate\n",
    "stt_model = WhisperModel(\"base\", device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "def get_text_from_base64(b64_string):\n",
    "    # Decode base64 to bytes\n",
    "    audio_data = base64.b64decode(b64_string)\n",
    "    audio_file = io.BytesIO(audio_data)\n",
    "    \n",
    "    # Transcribe\n",
    "    segments, _ = stt_model.transcribe(audio_file, beam_size=5)\n",
    "    return \" \".join([segment.text for segment in segments])\n",
    "\n",
    "# 2. Get the text\n",
    "transcribed_text = get_text_from_base64(aud_b64)\n",
    "\n",
    "# 3. Pass to your Ollama Model\n",
    "model = ChatOllama(model=\"qwen3-vl:8b\", temperature=0.8)\n",
    "\n",
    "# We send the transcription AS text because ChatOllama doesn't support the 'audio' block yet\n",
    "response = model.invoke([\n",
    "    HumanMessage(content=f\"The user provided an audio file that says: '{transcribed_text}'. Respond to it.\")\n",
    "])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec38ee-b4e5-4c98-8d5c-4178dff13877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
