{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff8e916-9368-47b0-b085-5e2fde77993b",
   "metadata": {},
   "source": [
    "# Dynamic Prompt\n",
    "<img src=\"./assets/LC_DynamicPrompts.png\" width=\"500\">\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f018f7-42c9-40d4-b934-43862ac40590",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c63873e-c341-4d5c-8d52-7a36c49032a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=****here\n",
      "LANGSMITH_API_KEY=****754b\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ials\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0080bb-d019-4da0-b75d-13e427173f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60346fe-505d-4edc-b4be-a43ae4fb88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RuntimeContext:\n",
    "    is_employee: bool\n",
    "    db: SQLDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44956582-7f68-4da5-8938-a77489795e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.runtime import get_runtime\n",
    "\n",
    "@tool\n",
    "def execute_sql(query: str) -> str:\n",
    "    \"\"\"Execute a SQLite command and return results.\"\"\"\n",
    "    runtime = get_runtime(RuntimeContext)\n",
    "    db = runtime.context.db\n",
    "\n",
    "    try:\n",
    "        return db.run(query)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b004b5-5582-4815-80af-0d3307db19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a careful SQLite analyst.\n",
    "\n",
    "Rules:\n",
    "- Think step-by-step.\n",
    "- When you need data, call the tool `execute_sql` with ONE SELECT query.\n",
    "- Read-only only; no INSERT/UPDATE/DELETE/ALTER/DROP/CREATE/REPLACE/TRUNCATE.\n",
    "- Limit to 5 rows unless the user explicitly asks otherwise.\n",
    "{table_limits}\n",
    "- If the tool returns 'Error:', revise the SQL and try again.\n",
    "- Prefer explicit column lists; avoid SELECT *.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797d816-d642-4f2d-839d-d9102e69cf72",
   "metadata": {},
   "source": [
    "## Build a Dynamic Prompt\n",
    "Utilize runtime context and middleware to generate a dynamic prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d033e009-bf20-46ff-9f58-0e531db16436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware.types import ModelRequest, dynamic_prompt\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_system_prompt(request: ModelRequest) -> str:\n",
    "    if not request.runtime.context.is_employee:\n",
    "        table_limits = \"- Limit access to these tables: Album, Artist, Genre, Playlist, PlaylistTrack, Track.\"\n",
    "    else:\n",
    "        table_limits = \"\"\n",
    "\n",
    "    return SYSTEM_PROMPT_TEMPLATE.format(table_limits=table_limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782e72f-12fa-4238-b84e-564818011785",
   "metadata": {},
   "source": [
    "Include middleware in `create_agent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8766cd53-763d-4745-980c-3fe60681f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5-coder:7b\", temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac312a68-5357-4156-ae65-15650057966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[execute_sql],\n",
    "    middleware=[dynamic_system_prompt],\n",
    "    context_schema=RuntimeContext,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f27e7f-0517-40d4-bd2c-b015563138dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the most costly purchase by Frank Harris?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To determine the most costly purchase by Frank Harris, we need to join the `Invoice` and `Customer` tables based on the customer ID. Then, filter the results to only include invoices for Frank Harris and sort them by the total cost in descending order to find the most expensive one.\n",
      "\n",
      "Here is the SQL query to achieve this:\n",
      "\n",
      "```sql\n",
      "SELECT i.InvoiceId, i.Total \n",
      "FROM Invoice i\n",
      "JOIN Customer c ON i.CustomerId = c.CustomerId\n",
      "WHERE c.FirstName = 'Frank' AND c.LastName = 'Harris'\n",
      "ORDER BY i.Total DESC\n",
      "LIMIT 1;\n",
      "```\n",
      "\n",
      "Let's execute this SQL query to get the result.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the most costly purchase by Frank Harris?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    context=RuntimeContext(is_employee=False, db=db),\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a90f6731-d76f-4698-a4a0-1805b0d2d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the most costly purchase by Frank Harris?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To find the most costly purchase by Frank Harris, we need to:\n",
      "\n",
      "1. Identify the table that contains purchase information.\n",
      "2. Filter the purchases to include only those made by Frank Harris.\n",
      "3. Determine the cost of each purchase.\n",
      "4. Find the purchase with the highest cost.\n",
      "\n",
      "Let's assume the table is named `purchases` and it has columns `customer_name`, `item_name`, and `cost`. We will use the following SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT item_name, MAX(cost) as max_cost\n",
      "FROM purchases\n",
      "WHERE customer_name = 'Frank Harris';\n",
      "```\n",
      "\n",
      "This query selects the most expensive item and its cost for Frank Harris.\n",
      "\n",
      "{\"name\": \"execute_sql\", \"arguments\": {\"query\": \"SELECT item_name, MAX(cost) as max_cost FROM purchases WHERE customer_name = 'Frank Harris' LIMIT 1\"}}\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the most costly purchase by Frank Harris?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    context=RuntimeContext(is_employee=True, db=db),\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036eb89-bd27-46f1-8dbe-670ac32b6f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f182c-f57c-4145-8511-561febc96859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2820a-76b8-4cb3-8e52-7c437ff2e97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f48e4f-fb5c-47fa-bd6f-091795b7bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import nest_asyncio\n",
    "from typing import Annotated, List, TypedDict, Literal\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# 1. Setup\n",
    "nest_asyncio.apply()\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "\n",
    "@tool\n",
    "def execute_sql(query: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Execute a SQLite command and return results.\"\"\"\n",
    "    database = config[\"configurable\"].get(\"db\")\n",
    "    try:\n",
    "        # Aggressive cleaning of the query string\n",
    "        clean_query = query.strip().strip(\"'\").strip('\"').replace('```sql', '').replace('```', '')\n",
    "        return str(database.run(clean_query))\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "tools = [execute_sql]\n",
    "tool_node = ToolNode(tools)\n",
    "llm = ChatOllama(model=\"qwen2.5-coder:7b\", temperature=0)\n",
    "\n",
    "# 2. THE FIX: Custom Routing Logic\n",
    "def manual_router(state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # Check if the model used the native tool_calls list\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # FALLBACK: If the model wrote a SQL query in the text, FORCE it to the tools node\n",
    "    content = last_message.content.upper()\n",
    "    if \"SELECT\" in content and \"FROM\" in content:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return \"__end__\"\n",
    "\n",
    "# 3. Model Node with Forced Parsing\n",
    "def call_model(state: AgentState, config: RunnableConfig):\n",
    "    is_employee = config[\"configurable\"].get(\"is_employee\", False)\n",
    "    database = config[\"configurable\"].get(\"db\")\n",
    "    \n",
    "    limits = \"Full access.\" if is_employee else \"ONLY access: Album, Artist, Genre, Track.\"\n",
    "    \n",
    "    sys_msg = SystemMessage(content=f\"\"\"You are a SQL analyst. \n",
    "    {limits}\n",
    "    ALWAYS use 'execute_sql' to get data. \n",
    "    If you need data, output ONLY the JSON for the tool call.\n",
    "    Schema: {database.get_table_info()}\"\"\")\n",
    "    \n",
    "    # Invoke model\n",
    "    response = llm.invoke([sys_msg] + state[\"messages\"])\n",
    "    \n",
    "    # If the model wrote a query but didn't trigger 'tool_calls', we fix the message object\n",
    "    if not response.tool_calls:\n",
    "        sql_match = re.search(r'SELECT\\s+.*?;', response.content, re.IGNORECASE | re.DOTALL)\n",
    "        if sql_match:\n",
    "            response.tool_calls = [{\n",
    "                \"name\": \"execute_sql\", \n",
    "                \"args\": {\"query\": sql_match.group()}, \n",
    "                \"id\": \"manual_fix\"\n",
    "            }]\n",
    "            \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 4. Build Graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", manual_router) # Uses our fixed router\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# 5. Run Test\n",
    "async def run_test(is_emp: bool):\n",
    "    print(f\"\\n--- Testing (Employee={is_emp}) ---\")\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\", \"db\": db, \"is_employee\": is_emp}}\n",
    "    async for event in app.astream({\"messages\": [HumanMessage(content=\"What is the total of Frank Harris's last invoice?\")]}, config):\n",
    "        for value in event.values():\n",
    "            value[\"messages\"][-1].pretty_print()\n",
    "\n",
    "await run_test(is_emp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab1fe1-82c6-4c0c-8996-b51db267b1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2000ea-5cbc-492d-8ae1-1d38fc65362d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18160f1-8935-4195-93b3-f143c80eee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nest_asyncio\n",
    "from dataclasses import dataclass\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# 1. Setup\n",
    "nest_asyncio.apply()\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "\n",
    "# 2. Tool with logic to access DB\n",
    "@tool\n",
    "def execute_sql(query: str) -> str:\n",
    "    \"\"\"Execute a SQLite command and return results.\"\"\"\n",
    "    try:\n",
    "        # Clean potential markdown/quotes from local LLM output\n",
    "        clean_query = query.strip().strip(\"'\").strip('\"').replace('```sql', '').replace('```', '')\n",
    "        return db.run(clean_query)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "tools = [execute_sql]\n",
    "tool_node = ToolNode(tools)\n",
    "llm = ChatOllama(model=\"qwen2.5-coder:7b\", temperature=0).bind_tools(tools)\n",
    "\n",
    "# 3. Dynamic System Prompt Logic\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a careful SQLite analyst.\n",
    "Rules:\n",
    "- Think step-by-step.\n",
    "- Call `execute_sql` with ONE SELECT query.\n",
    "- Read-only: no INSERT/UPDATE/DELETE.\n",
    "- Limit to 5 rows.\n",
    "{table_limits}\n",
    "- Return tool calls in JSON format.\n",
    "- Schema:\n",
    "{schema}\n",
    "\"\"\"\n",
    "\n",
    "# 4. Agent Node with Security Logic\n",
    "def call_model(state: MessagesState, config: dict):\n",
    "    # Retrieve security context from the config\n",
    "    is_employee = config.get(\"configurable\", {}).get(\"is_employee\", False)\n",
    "    \n",
    "    if not is_employee:\n",
    "        table_limits = \"- SECURITY: Limit access ONLY to: Album, Artist, Genre, Playlist, PlaylistTrack, Track. DO NOT access Invoice or Customer tables.\"\n",
    "    else:\n",
    "        table_limits = \"- SECURITY: You have full employee access to all tables including Customer and Invoice.\"\n",
    "\n",
    "    # Construct the dynamic prompt\n",
    "    sys_content = SYSTEM_PROMPT_TEMPLATE.format(\n",
    "        table_limits=table_limits,\n",
    "        schema=db.get_table_info()\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": sys_content}] + state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 5. Custom Router (The Fix for local JSON formatting)\n",
    "def custom_router(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    content = last_message.content.strip()\n",
    "    if content.startswith(\"{\") and \"name\" in content:\n",
    "        try:\n",
    "            tool_data = json.loads(content)\n",
    "            last_message.tool_calls = [{\n",
    "                \"name\": tool_data[\"name\"],\n",
    "                \"args\": tool_data[\"arguments\"],\n",
    "                \"id\": \"manual_call_id\"\n",
    "            }]\n",
    "            return \"tools\"\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return END\n",
    "\n",
    "# 6. Build Graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", custom_router)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# 7. Run Tests\n",
    "async def run_test(is_employee: bool, question: str):\n",
    "    print(f\"\\n--- Testing as {'Employee' if is_employee else 'Customer'} ---\")\n",
    "    config = {\"configurable\": {\"is_employee\": is_employee}}\n",
    "    inputs = {\"messages\": [(\"user\", question)]}\n",
    "    \n",
    "    async for chunk in app.astream(inputs, config=config, stream_mode=\"values\"):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# Run scenarios\n",
    "# 1. Customer asking for invoice (Should be blocked by prompt)\n",
    "await run_test(is_employee=False, question=\"What is the most costly purchase by Frank Harris?\")\n",
    "\n",
    "# 2. Employee asking for invoice (Should be allowed)\n",
    "await run_test(is_employee=True, question=\"What is the most costly purchase by Frank Harris?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efa8f8-b3a3-4c7c-a404-2196d99b335d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
