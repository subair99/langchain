{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190a3c14-4a67-4d64-9378-0b9737e4a5f7",
   "metadata": {},
   "source": [
    "# ‚úâÔ∏è Messages\n",
    "  <img src=\"./assets/LC_Messages.png\" width=\"500\">\n",
    "\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c566d2-7844-4901-af65-4a6e58817716",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6ad0d-4efd-4066-9a8d-ca8bb0de94ef",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa9fb12-98e3-490d-9ae6-885054c8f117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY=****eJgA\n",
      "LANGSMITH_API_KEY=****2eed\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ject\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f27b5-a53a-4f24-9480-6af61823d4e6",
   "metadata": {},
   "source": [
    "## Humanüë®‚Äçüíª and AI ü§ñ Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ca38b8-7514-4e18-b141-86f77c684ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\", \n",
    "    system_prompt=\"You are a full-stack comedian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e517775-cdac-43ab-a40b-1a9e8deaa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "result = agent.invoke({\"messages\": [human_msg]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bcefc1-53d7-4723-a3dc-d87983be761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey there! I‚Äôm doing well‚Äîstack is healthy, coffee levels are optimal, and I‚Äôve got a fresh batch of jokes ready. How are you?\n",
      "\n",
      "A couple quick techy one-liners to start:\n",
      "- Why do programmers prefer dark mode? Because light attracts bugs.\n",
      "- I would tell you a UDP joke, but you might not get it.\n",
      "- My code runs on coffee and sarcasm‚Äîmostly sarcasm.\n",
      "\n",
      "What can I help you with today? Want a joke, a debugging tip, a quick code snippet, or a plan for a stand-up bit about full-stack life?\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c37ca3-70f7-4f76-8108-94210ba7f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(result[\"messages\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e186f7e-8818-4de4-bebd-4f73cebe5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: Hello, how are you?\n",
      "\n",
      "ai: Hey there! I‚Äôm doing well‚Äîstack is healthy, coffee levels are optimal, and I‚Äôve got a fresh batch of jokes ready. How are you?\n",
      "\n",
      "A couple quick techy one-liners to start:\n",
      "- Why do programmers prefer dark mode? Because light attracts bugs.\n",
      "- I would tell you a UDP joke, but you might not get it.\n",
      "- My code runs on coffee and sarcasm‚Äîmostly sarcasm.\n",
      "\n",
      "What can I help you with today? Want a joke, a debugging tip, a quick code snippet, or a plan for a stand-up bit about full-stack life?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type}: {msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f30337-3873-4b0d-aeff-3c418f5dff32",
   "metadata": {},
   "source": [
    "### Altenative formats\n",
    "#### Strings\n",
    "There are situations where LangChain can infer the role from the context, and a simple string is enough to create a message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2450c1b-924a-422c-bac3-62b1f03dc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-nano\",\n",
    "    system_prompt=\"You are a terse sports poet.\",  # This is a SystemMessage under the hood\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf9a9f83-79d4-4abe-b1e3-45ef58d2f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseball: chalked diamond, sun on the infield.\n",
      "The pitcher winds; the ball answers with heat.\n",
      "The bat cracks; silence shatters, the crowd breathes.\n",
      "Leather speaks; gloves swallow ground.\n",
      "Three strikes, the inning exhales and dies.\n",
      "Four balls‚Äîwalk to first, a quiet advance.\n",
      "A stolen base‚Äîa blur of grass and steel.\n",
      "Nine innings, time stitched in dirt and hope.\n",
      "Rain delays, legends, late-inning miracles.\n",
      "Seventh-inning stretch; hats rise to the anthem.\n",
      "\n",
      "Baseball endures, old dream, fresh memory.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": \"Tell me about baseball\"})   # This is a HumanMessage under the hood\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1544d7-3590-42e9-a56b-0dfb34f28505",
   "metadata": {},
   "source": [
    "#### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b11e46-9c25-4828-9c6a-29a4594acdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sprinters surge forward\n",
      "Sun sears the track as feet scream\n",
      "Finish lines shiver\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"}}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00905cbe-b248-496f-898c-d223cd1fd0d7",
   "metadata": {},
   "source": [
    "There are multiple roles:\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sports poetry expert who completes haikus that have been started\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Feet don't fail me...\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b31b4c-00f0-4b37-8152-6f243590df8e",
   "metadata": {},
   "source": [
    "## Output Format\n",
    "### messages\n",
    "Let's create a tool so agent will create some tool messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27831c76-be27-4ee8-a24d-cc6d455f4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def check_haiku_lines(text: str):\n",
    "    \"\"\"Check if the given haiku text has exactly 3 lines.\n",
    "\n",
    "    Returns None if it's correct, otherwise an error message.\n",
    "    \"\"\"\n",
    "    # Split the text into lines, ignoring leading/trailing spaces\n",
    "    lines = [line.strip() for line in text.strip().splitlines() if line.strip()]\n",
    "    print(f\"checking haiku, it has {len(lines)} lines:\\n {text}\")\n",
    "\n",
    "    if len(lines) != 3:\n",
    "        return f\"Incorrect! This haiku has {len(lines)} lines. A haiku must have exactly 3 lines.\"\n",
    "    return \"Correct, this haiku has 3 lines.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879cad42-e41c-4d03-a118-585ff9dcfb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5\",\n",
    "    tools=[check_haiku_lines],\n",
    "    system_prompt=\"You are a sports poet who only writes Haiku. You always check your work.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a70fbb-1d26-411c-aa87-6077bdf21868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking haiku, it has 3 lines:\n",
      " Whistle splits cool air\n",
      "Stadium hearts drum in time\n",
      "Footsteps chase the dawn\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": \"Please write me a poem\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b3f31f-7247-4d9c-811d-48b041d8eb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Whistle splits cool air\\nStadium hearts drum in time\\nFootsteps chase the dawn'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "605faf3d-c76f-499d-abde-6fe0473eea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(result[\"messages\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91779142-2d3a-4e9e-9827-69c538e8f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please write me a poem\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  check_haiku_lines (call_uOLf0ZxcBTNBT2a77IZJi1jO)\n",
      " Call ID: call_uOLf0ZxcBTNBT2a77IZJi1jO\n",
      "  Args:\n",
      "    text: Whistle splits cool air\n",
      "Stadium hearts drum in time\n",
      "Footsteps chase the dawn\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: check_haiku_lines\n",
      "\n",
      "Correct, this haiku has 3 lines.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Whistle splits cool air\n",
      "Stadium hearts drum in time\n",
      "Footsteps chase the dawn\n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c704dd-baf5-4afd-a89c-ef3790fe1310",
   "metadata": {},
   "source": [
    "### Other useful information\n",
    "Above, the print messages have just been selecting pieces of the information stored in the messages list. Let's dig into all the information that is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1afcfa8-a706-403f-8c29-1f441d174908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Please write me a poem', additional_kwargs={}, response_metadata={}, id='13b18ae4-f92e-4582-925a-39d7984806a8'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 555, 'prompt_tokens': 170, 'total_tokens': 725, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CQbI0V3W0uPCDlcnD4GYTydYxCsAJ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--0055426a-ee06-4daa-a36c-4074fa9c1ceb-0', tool_calls=[{'name': 'check_haiku_lines', 'args': {'text': 'Whistle splits cool air\\nStadium hearts drum in time\\nFootsteps chase the dawn'}, 'id': 'call_uOLf0ZxcBTNBT2a77IZJi1jO', 'type': 'tool_call'}], usage_metadata={'input_tokens': 170, 'output_tokens': 555, 'total_tokens': 725, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}),\n",
       "  ToolMessage(content='Correct, this haiku has 3 lines.', name='check_haiku_lines', id='5aff8da9-c8c0-4bed-b8d4-7bf884a8c097', tool_call_id='call_uOLf0ZxcBTNBT2a77IZJi1jO'),\n",
       "  AIMessage(content='Whistle splits cool air\\nStadium hearts drum in time\\nFootsteps chase the dawn', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 231, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CQbIATueaDYKiqYDNX5xKHjKGWCr5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--61eb6a33-1bda-46d7-8d00-f3aaea2487a3-0', usage_metadata={'input_tokens': 231, 'output_tokens': 21, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0568f-41d7-48e3-b69e-f2b8123d941a",
   "metadata": {},
   "source": [
    "You can select just the last message, and you can see where the final message is coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bacc660-7997-4da7-9d3e-eee4b8119601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Whistle splits cool air\\nStadium hearts drum in time\\nFootsteps chase the dawn', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 231, 'total_tokens': 252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CQbIATueaDYKiqYDNX5xKHjKGWCr5', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--61eb6a33-1bda-46d7-8d00-f3aaea2487a3-0', usage_metadata={'input_tokens': 231, 'output_tokens': 21, 'total_tokens': 252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7254b9e5-f6ac-432e-bf9a-05676f8e4b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 231,\n",
       " 'output_tokens': 21,\n",
       " 'total_tokens': 252,\n",
       " 'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       " 'output_token_details': {'audio': 0, 'reasoning': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "523f453e-a425-4df0-88b0-a04e6e7612ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 21,\n",
       "  'prompt_tokens': 231,\n",
       "  'total_tokens': 252,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_provider': 'openai',\n",
       " 'model_name': 'gpt-5-2025-08-07',\n",
       " 'system_fingerprint': None,\n",
       " 'id': 'chatcmpl-CQbIATueaDYKiqYDNX5xKHjKGWCr5',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5d505-a2db-4f64-9346-03af057b3be6",
   "metadata": {},
   "source": [
    "### Try it on your own!\n",
    "Change the system prompt, use the `pretty_printer` to print some messages or dig through `results` on your own. Notice the Human, AI and Tool messages and some of their associated metadata. Notice how the final results provide a complete history of the agents activity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f921687f-005c-4727-b041-18bafbfaf1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5\",\n",
    "    tools=[check_haiku_lines],\n",
    "    system_prompt=\"Your SYSTEM prompt here\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e27be2-6bf9-4c0e-b466-8f9e483bfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
