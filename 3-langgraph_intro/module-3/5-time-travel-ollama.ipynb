{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9902a6a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/time-travel.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239536-lesson-5-time-travel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba98beac-d461-4d7d-878a-11beca03ea1c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Time travel\n",
    "\n",
    "## Review\n",
    "\n",
    "We discussed motivations for human-in-the-loop:\n",
    "\n",
    "(1) `Approval` - We can interrupt our agent, surface state to a user, and allow the user to accept an action\n",
    "\n",
    "(2) `Debugging` - We can rewind the graph to reproduce or avoid issues\n",
    "\n",
    "(3) `Editing` - You can modify the state \n",
    "\n",
    "We showed how breakpoints can stop the graph at specific nodes or allow the graph to dynamically interrupt itself.\n",
    "\n",
    "Then we showed how to proceed with human approval or directly edit the graph state with human feedback.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's show how LangGraph [supports debugging](https://docs.langchain.com/oss/python/langgraph/use-time-travel) by viewing, re-playing, and even forking from past states. \n",
    "\n",
    "We call this `time travel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d32093f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497d316-832a-4668-b133-fd317ee81220",
   "metadata": {},
   "source": [
    "Let's build our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8aa4400-769a-4562-9a81-c08bd3ebbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "model = ChatOllama(model=\"qwen3:8b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64ab3a1-b39c-4176-88c7-791a0b80c725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = model\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8622a9-57cd-44dc-8696-46c5ab32d0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab18a04-1329-47ac-a25b-4e01bf756e2a",
   "metadata": {},
   "source": [
    "Let's run it, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b2ab62-82bc-4356-8d5b-2d4f49069fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (effe8730-fe40-4b27-9b1f-da3aff489a06)\n",
      " Call ID: effe8730-fe40-4b27-9b1f-da3aff489a06\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The product of 2 and 3 is **6**.  \n",
      "\n",
      "Let me know if you need help with anything else! üòä\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268cfa43-22d1-4d63-8d81-a3ce00f1f2c8",
   "metadata": {},
   "source": [
    "## Browsing History\n",
    "\n",
    "We can use `get_state` to look at the **current** state of our graph, given the `thread_id`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161eb053-18f6-4c99-8674-8cbd11cae57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='a467276d-1e41-4d1e-8ab9-e2d5e5ef26e9'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2026-01-23T15:17:37.017939904Z', 'done': True, 'done_reason': 'stop', 'total_duration': 60328477229, 'load_duration': 505970676, 'prompt_eval_count': 291, 'prompt_eval_duration': 641834771, 'eval_count': 111, 'eval_duration': 36135286212, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'}, id='lc_run--019beb6d-becb-7f40-8385-42e2cd85e6e1-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'effe8730-fe40-4b27-9b1f-da3aff489a06', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 291, 'output_tokens': 111, 'total_tokens': 402}), ToolMessage(content='6', name='multiply', id='c3cbdbd5-928d-4231-aa82-276f43d9623d', tool_call_id='effe8730-fe40-4b27-9b1f-da3aff489a06'), AIMessage(content='The product of 2 and 3 is **6**.  \\n\\nLet me know if you need help with anything else! üòä', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2026-01-23T15:18:24.35852089Z', 'done': True, 'done_reason': 'stop', 'total_duration': 47317762784, 'load_duration': 243711077, 'prompt_eval_count': 327, 'prompt_eval_duration': 7063032213, 'eval_count': 121, 'eval_duration': 39919727352, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'}, id='lc_run--019beb6e-aa8e-7f23-94e1-33dbd3c71ced-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 327, 'output_tokens': 121, 'total_tokens': 448})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86ec-29ce-64fe-8003-698b789e2af5'}}, metadata={'source': 'loop', 'step': 3, 'parents': {}}, created_at='2026-01-23T15:18:24.363827+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86ea-6670-6875-8002-f25a65a43a14'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00869e-7b41-4d71-ad3c-cacf8f9c029f",
   "metadata": {},
   "source": [
    "We can also browse the state history of our agent.\n",
    "\n",
    "`get_state_history` lets us get the state at all prior steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3010169c-3bfa-498c-a30c-7ba53744e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [s for s in graph.get_state_history(thread)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4612ccf-59fc-4848-8845-0433fee2ca8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af30f269-1152-4fa1-a7c6-2947acad9a27",
   "metadata": {},
   "source": [
    "The first element is the current state, just as we got from `get_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e60b292-8efc-4cc3-b836-51f060fa608b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='a467276d-1e41-4d1e-8ab9-e2d5e5ef26e9')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86e8-26dd-6ef7-8000-f2d4d2de72b9'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-23T15:16:36.681475+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86e8-26d9-6340-bfff-43947ace9bc9'}}, tasks=(PregelTask(id='de6afa7b-58a0-03a8-bee6-c290698257b3', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2026-01-23T15:17:37.017939904Z', 'done': True, 'done_reason': 'stop', 'total_duration': 60328477229, 'load_duration': 505970676, 'prompt_eval_count': 291, 'prompt_eval_duration': 641834771, 'eval_count': 111, 'eval_duration': 36135286212, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'}, id='lc_run--019beb6d-becb-7f40-8385-42e2cd85e6e1-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'effe8730-fe40-4b27-9b1f-da3aff489a06', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 291, 'output_tokens': 111, 'total_tokens': 402})]}),), interrupts=())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states[-2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4148a710-ceed-413b-b93c-070c6c792fa2",
   "metadata": {},
   "source": [
    "Everything above we can visualize here: \n",
    "\n",
    "![fig1.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb038211b544898570be3_time-travel1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5ad554a-faf3-489f-a9a9-774f4ec2a526",
   "metadata": {},
   "source": [
    "## Replaying \n",
    "\n",
    "We can re-run our agent from any of the prior steps.\n",
    "\n",
    "![fig2.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb038a0bd34b541c78fb8_time-travel2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e135d2db-d613-42da-877e-d429f21aaefd",
   "metadata": {},
   "source": [
    "Let's look back at the step that recieved human input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3688e511-a440-4330-a450-e5ed889c3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = all_states[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72adf296-d519-4bdc-af03-3b29799e9534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='a467276d-1e41-4d1e-8ab9-e2d5e5ef26e9')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86e8-26dd-6ef7-8000-f2d4d2de72b9'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-01-23T15:16:36.681475+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86e8-26d9-6340-bfff-43947ace9bc9'}}, tasks=(PregelTask(id='de6afa7b-58a0-03a8-bee6-c290698257b3', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2026-01-23T15:17:37.017939904Z', 'done': True, 'done_reason': 'stop', 'total_duration': 60328477229, 'load_duration': 505970676, 'prompt_eval_count': 291, 'prompt_eval_duration': 641834771, 'eval_count': 111, 'eval_duration': 36135286212, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'}, id='lc_run--019beb6d-becb-7f40-8385-42e2cd85e6e1-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'effe8730-fe40-4b27-9b1f-da3aff489a06', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 291, 'output_tokens': 111, 'total_tokens': 402})]}),), interrupts=())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e7894-6546-48ff-9c25-fa6d120391b3",
   "metadata": {},
   "source": [
    "Look at the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe69428-f364-4330-bf5d-aa966c7f3b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='a467276d-1e41-4d1e-8ab9-e2d5e5ef26e9')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2df545-cc80-4962-a34a-faac7af8eb3d",
   "metadata": {},
   "source": [
    "We can see the next node to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2f333f9-9b2b-46f6-ac3a-525f86b20f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('assistant',)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8938c18-5c22-47df-b71e-40afa73c87af",
   "metadata": {},
   "source": [
    "We also get the config, which tells us the `checkpoint_id` as well as the `thread_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1298786-afa5-4277-927e-708a8629231b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0f86e8-26dd-6ef7-8000-f2d4d2de72b9'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93b5eb-f541-4f82-93b1-48f54bf5cf83",
   "metadata": {},
   "source": [
    "To replay from here, we simply pass the config back to the agent!\n",
    "\n",
    "The graph knows that this checkpoint has aleady been executed. \n",
    "\n",
    "It just re-plays from this checkpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "531b4cd1-54f6-44aa-9ffe-cf5403dad65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (137f7007-78c1-49c0-8896-189cca69c6e6)\n",
      " Call ID: 137f7007-78c1-49c0-8896-189cca69c6e6\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The product of 2 and 3 is **6**.  \n",
      "\n",
      "Let me know if you need help with anything else! üòä\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a914e-63e6-4424-970f-15059ce9b4c3",
   "metadata": {},
   "source": [
    "Now, we can see our current state after the agent re-ran."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a5a1f03-19f2-4d22-ba54-1c065ff08e85",
   "metadata": {},
   "source": [
    "## Forking\n",
    "\n",
    "What if we want to run from that same step, but with a different input.\n",
    "\n",
    "This is forking.\n",
    "\n",
    "![fig3.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb038f89f2d847ee5c336_time-travel3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdeb5bf2-1566-4d8c-8ea5-65894e3a7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='a467276d-1e41-4d1e-8ab9-e2d5e5ef26e9')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork = all_states[-2]\n",
    "to_fork.values[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15f6a6-6eaa-48d6-92bb-864ea3a31b6a",
   "metadata": {},
   "source": [
    "Again, we have the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1621b27-ee51-4dc3-81c4-1d05317280db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0f86e8-26dd-6ef7-8000-f2d4d2de72b9'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2102195-0583-4dbe-ad2f-02fac7915585",
   "metadata": {},
   "source": [
    "Let's modify the state at this checkpoint.\n",
    "\n",
    "We can just run `update_state` with the `checkpoint_id` supplied. \n",
    "\n",
    "Remember how our reducer on `messages` works: \n",
    "\n",
    "* It will append, unless we supply a message ID.\n",
    "* We supply the message ID to overwrite the message, rather than appending to state!\n",
    "\n",
    "So, to overwrite the the message, we just supply the message ID, which we have `to_fork.values[\"messages\"].id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b4a918d-858a-41ac-a5d4-e99260e2d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fork_config = graph.update_state(\n",
    "    to_fork.config,\n",
    "    {\"messages\": [HumanMessage(content='Multiply 5 and 3', \n",
    "                               id=to_fork.values[\"messages\"][0].id)]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ff4e9bb-8221-42d1-b7d0-b0cbd5dc374a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0f86f0-6aa8-6741-8001-87275d9e29ae'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fork_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebfe6fd-c94b-4291-a125-ec6170e35bc5",
   "metadata": {},
   "source": [
    "This creates a new, forked checkpoint.\n",
    " \n",
    "But, the metadata - e.g., where to go next - is perserved! \n",
    "\n",
    "We can see the current state of our agent has been updated with our fork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "586ce86c-1257-45e9-ba30-6287932b9484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='a467276d-1e41-4d1e-8ab9-e2d5e5ef26e9')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states = [state for state in graph.get_state_history(thread) ]\n",
    "all_states[0].values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e19798-25d8-49e8-8542-13d2b3bdf58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='a467276d-1e41-4d1e-8ab9-e2d5e5ef26e9')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86f0-6aa8-6741-8001-87275d9e29ae'}}, metadata={'source': 'update', 'step': 1, 'parents': {}}, created_at='2026-01-23T15:20:18.538231+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86e8-26dd-6ef7-8000-f2d4d2de72b9'}}, tasks=(PregelTask(id='5879b228-f644-08db-bc96-686c719e353b', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c641e2-b8e9-4461-b854-8725006a5eb6",
   "metadata": {},
   "source": [
    "Now, when we stream, the graph knows this checkpoint has never been executed.\n",
    "\n",
    "So, the graph runs, rather than simply re-playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c49f2a8-b325-45e4-b36c-17fab1b37cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 5 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (4c428580-a3dd-40e3-9898-c4be147ed783)\n",
      " Call ID: 4c428580-a3dd-40e3-9898-c4be147ed783\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "15\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The product of 5 and 3 is 15.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, fork_config, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d7f80-ee60-4147-b51f-ee3b0cf5cbba",
   "metadata": {},
   "source": [
    "Now, we can see the current state is the end of our agent run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "132ef840-64c7-479c-ad34-3f177f4b2524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='a467276d-1e41-4d1e-8ab9-e2d5e5ef26e9'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2026-01-23T15:20:55.549890497Z', 'done': True, 'done_reason': 'stop', 'total_duration': 36920413268, 'load_duration': 294104935, 'prompt_eval_count': 291, 'prompt_eval_duration': 1434338429, 'eval_count': 104, 'eval_duration': 35084861700, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'}, id='lc_run--019beb71-21bd-73b2-ab20-1c063d7b07a6-0', tool_calls=[{'name': 'multiply', 'args': {'a': 5, 'b': 3}, 'id': '4c428580-a3dd-40e3-9898-c4be147ed783', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 291, 'output_tokens': 104, 'total_tokens': 395}), ToolMessage(content='15', name='multiply', id='50246819-510e-4e7f-b751-0afc92f86766', tool_call_id='4c428580-a3dd-40e3-9898-c4be147ed783'), AIMessage(content='The product of 5 and 3 is 15.', additional_kwargs={}, response_metadata={'model': 'qwen3:8b', 'created_at': '2026-01-23T15:21:49.680584928Z', 'done': True, 'done_reason': 'stop', 'total_duration': 54108038065, 'load_duration': 261678787, 'prompt_eval_count': 328, 'prompt_eval_duration': 4736814627, 'eval_count': 137, 'eval_duration': 48971122426, 'logprobs': None, 'model_name': 'qwen3:8b', 'model_provider': 'ollama'}, id='lc_run--019beb71-b210-7310-a0c3-e40e1c7a242b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 328, 'output_tokens': 137, 'total_tokens': 465})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86f3-cfec-677d-8004-eee5362b305b'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2026-01-23T15:21:49.687361+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0f86f1-cbc7-6adc-8003-4d40892b4a7a'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ceb5f31-97b0-466c-9b3b-ae4df7cd462a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Time travel with LangGraph API\n",
    "\n",
    "**‚ö†Ô∏è Notice**\n",
    "\n",
    "Since filming these videos, we've updated Studio so that it can now be run locally and accessed through your browser. This is the preferred way to run Studio instead of using the Desktop App shown in the video. It is now called _LangSmith Studio_ instead of _LangGraph Studio_. Detailed setup instructions are available in the \"Getting Setup\" guide at the start of the course. You can find a description of Studio [here](https://docs.langchain.com/langsmith/studio), and specific details for local deployment [here](https://docs.langchain.com/langsmith/quick-start-studio#local-development-server).  \n",
    "To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- üöÄ API: http://127.0.0.1:2024\n",
    "- üé® Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- üìö API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the **Studio UI** URL shown above.\n",
    "\n",
    "We connect to it via the SDK and show how the LangGraph API [supports time travel](https://docs.langchain.com/langsmith/human-in-the-loop-time-travel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "891defdb-746c-48e4-8efa-bb5f138dc4bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a317925d-1788-4cfc-9c12-336b17b4d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://127.0.0.1:2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d5e03-0ab8-4c7f-a1ee-f410b6aadc03",
   "metadata": {},
   "source": [
    "#### Re-playing \n",
    "\n",
    "Let's run our agent streaming `updates` to the state of the graph after each node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d4d01da-7b64-4c92-96b7-29ec93332d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Assistant Node--------------------\n",
      "{'content': '<function_call>{\"name\": \"multiply\", \"arguments\": {\"a\": 2, \"b\": 3}}</function_call>', 'additional_kwargs': {}, 'response_metadata': {'model': 'granite3.3:8b', 'created_at': '2026-01-23T15:27:32.795256071Z', 'done': True, 'done_reason': 'stop', 'total_duration': 324167663802, 'load_duration': 275906324050, 'prompt_eval_count': 215, 'prompt_eval_duration': 37080032333, 'eval_count': 32, 'eval_duration': 10858684243, 'logprobs': None, 'model_name': 'granite3.3:8b', 'model_provider': 'ollama'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019beb72-ce54-7182-95eb-51788f0957e8-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 215, 'output_tokens': 32, 'total_tokens': 247}}\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id = \"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    if chunk.data:\n",
    "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
    "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
    "        if assisant_node:\n",
    "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
    "            print(assisant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc3bab2",
   "metadata": {},
   "source": [
    "Now, let's look at **replaying** from a specified checkpoint. \n",
    "\n",
    "We simply need to pass the `checkpoint_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8ecc4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'Multiply 2 and 3',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': '67ac63a3-c9e9-46e3-b343-b96fda604acb'}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': 'c17e7088-9fdf-8835-0be6-982174f02316',\n",
       "   'name': 'assistant',\n",
       "   'path': ['__pregel_pull', 'assistant'],\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'checkpoint': None,\n",
       "   'state': None,\n",
       "   'result': {'messages': [{'content': '<function_call>{\"name\": \"multiply\", \"arguments\": {\"a\": 2, \"b\": 3}}</function_call>',\n",
       "      'additional_kwargs': {},\n",
       "      'response_metadata': {'model': 'granite3.3:8b',\n",
       "       'created_at': '2026-01-23T15:27:32.795256071Z',\n",
       "       'done': True,\n",
       "       'done_reason': 'stop',\n",
       "       'total_duration': 324167663802,\n",
       "       'load_duration': 275906324050,\n",
       "       'prompt_eval_count': 215,\n",
       "       'prompt_eval_duration': 37080032333,\n",
       "       'eval_count': 32,\n",
       "       'eval_duration': 10858684243,\n",
       "       'logprobs': None,\n",
       "       'model_name': 'granite3.3:8b',\n",
       "       'model_provider': 'ollama'},\n",
       "      'type': 'ai',\n",
       "      'name': None,\n",
       "      'id': 'lc_run--019beb72-ce54-7182-95eb-51788f0957e8-0',\n",
       "      'tool_calls': [],\n",
       "      'invalid_tool_calls': [],\n",
       "      'usage_metadata': {'input_tokens': 215,\n",
       "       'output_tokens': 32,\n",
       "       'total_tokens': 247}}]}}],\n",
       " 'metadata': {'graph_id': 'agent',\n",
       "  'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       "  'user_id': '',\n",
       "  'created_by': 'system',\n",
       "  'run_attempt': 1,\n",
       "  'langgraph_version': '1.0.6',\n",
       "  'langgraph_api_version': '0.6.39',\n",
       "  'langgraph_plan': 'developer',\n",
       "  'langgraph_host': 'self-hosted',\n",
       "  'langgraph_api_url': 'http://127.0.0.1:2024',\n",
       "  'run_id': '019beb72-c945-7580-aa42-b36dd4ce322d',\n",
       "  'thread_id': 'dec2c541-a332-492b-88ca-380f6192a3f6',\n",
       "  'source': 'loop',\n",
       "  'step': 0,\n",
       "  'parents': {},\n",
       "  'langgraph_request_id': 'c70ea33b-4cea-44e6-b6f1-339ebdd16f4e',\n",
       "  'langgraph_auth_user_id': ''},\n",
       " 'created_at': '2026-01-23T15:22:08.202308+00:00',\n",
       " 'checkpoint': {'checkpoint_id': '1f0f86f4-807f-605d-8000-c05f445557c0',\n",
       "  'thread_id': 'dec2c541-a332-492b-88ca-380f6192a3f6',\n",
       "  'checkpoint_ns': ''},\n",
       " 'parent_checkpoint': {'checkpoint_id': '1f0f86f4-7fab-6ed5-bfff-e098d4d5d926',\n",
       "  'thread_id': 'dec2c541-a332-492b-88ca-380f6192a3f6',\n",
       "  'checkpoint_ns': ''},\n",
       " 'interrupts': [],\n",
       " 'checkpoint_id': '1f0f86f4-807f-605d-8000-c05f445557c0',\n",
       " 'parent_checkpoint_id': '1f0f86f4-7fab-6ed5-bfff-e098d4d5d926'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])\n",
    "to_replay = states[-2]\n",
    "to_replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f865a",
   "metadata": {},
   "source": [
    "Let's stream with `stream_mode=\"values\"` to see the full state at every node as we replay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "325e8272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "{'run_id': '019beb77-c74f-7e41-ad13-19b16f9dc79c', 'attempt': 1}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: values...\n",
      "{'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '67ac63a3-c9e9-46e3-b343-b96fda604acb'}]}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: values...\n",
      "{'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '67ac63a3-c9e9-46e3-b343-b96fda604acb'}, {'content': '<function_call>{\"name\": \"multiply\", \"arguments\": {\"a\": 2, \"b\": 3}}</function_call>', 'additional_kwargs': {}, 'response_metadata': {'model': 'granite3.3:8b', 'created_at': '2026-01-23T15:27:46.438003347Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11345445944, 'load_duration': 220107426, 'prompt_eval_count': 215, 'prompt_eval_duration': 452325732, 'eval_count': 32, 'eval_duration': 10615773996, 'logprobs': None, 'model_name': 'granite3.3:8b', 'model_provider': 'ollama'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019beb77-ca8e-7872-8857-507f31b7e067-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 215, 'output_tokens': 32, 'total_tokens': 247}}]}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    checkpoint_id=to_replay['checkpoint_id']\n",
    "):      \n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    print(chunk.data)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c153b3",
   "metadata": {},
   "source": [
    "We can all view this as streaming only `updates` to state made by the nodes that we reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e608e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Assistant Node--------------------\n",
      "{'content': '<function_call>{\"name\": \"multiply\", \"arguments\": {\"a\": 2, \"b\": 3}}</function_call>', 'additional_kwargs': {}, 'response_metadata': {'model': 'granite3.3:8b', 'created_at': '2026-01-23T15:27:58.489813759Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11407756814, 'load_duration': 396370600, 'prompt_eval_count': 215, 'prompt_eval_duration': 374420378, 'eval_count': 32, 'eval_duration': 10586300157, 'logprobs': None, 'model_name': 'granite3.3:8b', 'model_provider': 'ollama'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019beb77-f981-77c0-93e6-02cfb1f423c6-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 215, 'output_tokens': 32, 'total_tokens': 247}}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"updates\",\n",
    "    checkpoint_id=to_replay['checkpoint_id']\n",
    "):\n",
    "    if chunk.data:\n",
    "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
    "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
    "        if assisant_node:\n",
    "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
    "            print(assisant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e66e0e8",
   "metadata": {},
   "source": [
    "#### Forking\n",
    "\n",
    "Now, let's look at forking.\n",
    "\n",
    "Let's get the same step as we worked with above, the human input.\n",
    "\n",
    "Let's create a new thread with our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01af5ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Assistant Node--------------------\n",
      "{'content': '<function_call>{\"name\": \"multiply\", \"arguments\": {\"a\": 2, \"b\": 3}}</function_call>', 'additional_kwargs': {}, 'response_metadata': {'model': 'granite3.3:8b', 'created_at': '2026-01-23T15:28:10.260822354Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11141398460, 'load_duration': 153130878, 'prompt_eval_count': 215, 'prompt_eval_duration': 406649808, 'eval_count': 32, 'eval_duration': 10524507542, 'logprobs': None, 'model_name': 'granite3.3:8b', 'model_provider': 'ollama'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019beb78-2887-73e2-815d-aac64ea7b02e-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 215, 'output_tokens': 32, 'total_tokens': 247}}\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    if chunk.data:\n",
    "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
    "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
    "        if assisant_node:\n",
    "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
    "            print(assisant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dbc8795-c3f5-4559-a00e-dc410c0a927f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Multiply 2 and 3',\n",
       "   'additional_kwargs': {},\n",
       "   'response_metadata': {},\n",
       "   'type': 'human',\n",
       "   'name': None,\n",
       "   'id': 'fa360bd9-7ab7-49d4-b776-a030d97e0560'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])\n",
    "to_fork = states[-2]\n",
    "to_fork['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11e6cde1-0388-43ea-b994-1c4e9ca1199b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fa360bd9-7ab7-49d4-b776-a030d97e0560'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork['values']['messages'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c1e2300-c8b2-4994-a96d-1be19c04b6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assistant']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d31d5aa-524f-42f4-ba7e-713a029610d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1f0f8701-92fa-60c4-8000-99a47766b7d0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork['checkpoint_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11e1d9-9fe7-4243-a06f-9b07e38a12ad",
   "metadata": {},
   "source": [
    "Let's edit the state.\n",
    "\n",
    "Remember how our reducer on `messages` works: \n",
    "\n",
    "* It will append, unless we supply a message ID.\n",
    "* We supply the message ID to overwrite the message, rather than appending to state!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0198f1b8-2f57-4c6e-ac6a-c6fb80cce0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_input = {\"messages\": HumanMessage(content=\"Multiply 3 and 3\",\n",
    "                                         id=to_fork['values']['messages'][0]['id'])}\n",
    "\n",
    "forked_config = await client.threads.update_state(\n",
    "    thread[\"thread_id\"],\n",
    "    forked_input,\n",
    "    checkpoint_id=to_fork['checkpoint_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dcd5b8e-6bb1-4967-84cf-4af710b8bf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkpoint': {'thread_id': '15e03fd9-92dc-4a52-96c8-41dafb7773f8',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0f8702-002a-6729-8001-349cc19b961e'},\n",
       " 'configurable': {'thread_id': '15e03fd9-92dc-4a52-96c8-41dafb7773f8',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0f8702-002a-6729-8001-349cc19b961e'},\n",
       " 'checkpoint_id': '1f0f8702-002a-6729-8001-349cc19b961e'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forked_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "015ac68a-5cc1-4c42-90a2-5b2b4865a153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'Multiply 3 and 3',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': 'fa360bd9-7ab7-49d4-b776-a030d97e0560'}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': '8f1e1bc5-80ed-1e1d-c5ce-321ff6c8cbe9',\n",
       "   'name': 'assistant',\n",
       "   'path': ['__pregel_pull', 'assistant'],\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'checkpoint': None,\n",
       "   'state': None,\n",
       "   'result': None}],\n",
       " 'metadata': {'graph_id': 'agent',\n",
       "  'thread_id': '15e03fd9-92dc-4a52-96c8-41dafb7773f8',\n",
       "  'checkpoint_id': '1f0f8701-92fa-60c4-8000-99a47766b7d0',\n",
       "  'checkpoint_ns': '',\n",
       "  'source': 'update',\n",
       "  'step': 1,\n",
       "  'parents': {}},\n",
       " 'created_at': '2026-01-23T15:28:10.555523+00:00',\n",
       " 'checkpoint': {'checkpoint_id': '1f0f8702-002a-6729-8001-349cc19b961e',\n",
       "  'thread_id': '15e03fd9-92dc-4a52-96c8-41dafb7773f8',\n",
       "  'checkpoint_ns': ''},\n",
       " 'parent_checkpoint': {'checkpoint_id': '1f0f8701-92fa-60c4-8000-99a47766b7d0',\n",
       "  'thread_id': '15e03fd9-92dc-4a52-96c8-41dafb7773f8',\n",
       "  'checkpoint_ns': ''},\n",
       " 'interrupts': [],\n",
       " 'checkpoint_id': '1f0f8702-002a-6729-8001-349cc19b961e',\n",
       " 'parent_checkpoint_id': '1f0f8701-92fa-60c4-8000-99a47766b7d0'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])\n",
    "states[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de80029-b987-49c5-890d-6cd70cbc8de7",
   "metadata": {},
   "source": [
    "To rerun, we pass in the `checkpoint_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da005240-d3f0-4c89-9aca-dfcb5d410ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Assistant Node--------------------\n",
      "{'content': '<function_call>{\"name\": \"multiply\", \"arguments\": {\"a\": 3, \"b\": 3}}</function_call>', 'additional_kwargs': {}, 'response_metadata': {'model': 'granite3.3:8b', 'created_at': '2026-01-23T15:28:23.929823435Z', 'done': True, 'done_reason': 'stop', 'total_duration': 12284367615, 'load_duration': 171191406, 'prompt_eval_count': 215, 'prompt_eval_duration': 1420163878, 'eval_count': 32, 'eval_duration': 10580201363, 'logprobs': None, 'model_name': 'granite3.3:8b', 'model_provider': 'ollama'}, 'type': 'ai', 'name': None, 'id': 'lc_run--019beb78-5979-78a0-b3a1-d181a25736f8-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 215, 'output_tokens': 32, 'total_tokens': 247}}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"updates\",\n",
    "    checkpoint_id=forked_config['checkpoint_id']\n",
    "):\n",
    "    if chunk.data:\n",
    "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
    "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
    "        if assisant_node:\n",
    "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
    "            print(assisant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36956571-a2b8-4f1b-8e30-51f02f155a6f",
   "metadata": {},
   "source": [
    "### LangGraph Studio\n",
    "\n",
    "Let's look at forking in the Studio UI with our `agent`, which uses `module-1/studio/agent.py` set in `module-1/studio/langgraph.json`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
