{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f3905b",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 5em\">ðŸ¦œ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bd8e5-f539-4f58-822c-2db46990f4bd",
   "metadata": {},
   "source": [
    "# __LangGraph Essentials__\n",
    "# Build A Workflow\n",
    "<div style=\"display:flex; align-items:flex-start;\">\n",
    "  <img src=\"../assets/EmailWorkflow.png\" width=\"600\" style=\"margin-right:15px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea634b-118c-4204-9385-c17a77ca62d1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f1916-5a59-4ea4-a9fb-35c9eae39b63",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda43634-cfde-45c3-ac0c-00203a11ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find file .env.\n",
      "This is used to double check the key settings for the notebook.\n",
      "This is just a check and is not required.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14584f8e-8ab3-402d-8fef-d88783f21b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "from typing import Literal, TypedDict\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5206c1",
   "metadata": {},
   "source": [
    "# Define state schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0864ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailClassification(TypedDict):\n",
    "    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n",
    "    topic: str\n",
    "    summary: str\n",
    "\n",
    "class EmailAgentState(TypedDict):\n",
    "    # Raw email data\n",
    "    email_content: str\n",
    "    sender_email: str\n",
    "    email_id: str\n",
    "\n",
    "    # Classification result\n",
    "    classification: EmailClassification | None\n",
    "\n",
    "    # Bug tracking\n",
    "    ticket_id: str | None\n",
    "\n",
    "    # Raw search results\n",
    "    search_results: list[str] | None\n",
    "    customer_history: dict | None\n",
    "\n",
    "    # Generated content\n",
    "    draft_response: str | None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db6048",
   "metadata": {},
   "source": [
    "# Define Nodes, Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaecaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "def read_email(state: EmailAgentState) -> EmailAgentState:\n",
    "    \"\"\"Extract and parse email content\"\"\"\n",
    "    pass\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3:14b\", temperature=0)\n",
    "\n",
    "def classify_intent(state: EmailAgentState) -> EmailAgentState:\n",
    "    \"\"\"Use LLM to classify email intent and urgency, then route accordingly\"\"\"\n",
    "\n",
    "    # Create structured LLM that returns EmailClassification dict\n",
    "    structured_llm = llm.with_structured_output(EmailClassification)\n",
    "\n",
    "    classification_prompt = f\"\"\"\n",
    "    Analyze this customer email and classify it:\n",
    "\n",
    "    Email: {state['email_content']}\n",
    "    From: {state['sender_email']}\n",
    "\n",
    "    Provide classification, including intent, urgency, topic, and summary\n",
    "    \"\"\"\n",
    "\n",
    "    # Get structured response directly as a dict\n",
    "    classification = structured_llm.invoke(classification_prompt)\n",
    "\n",
    "    # Store classification as a single dict in state\n",
    "    return {\"classification\": classification}\n",
    "\n",
    "def search_documentation(state: EmailAgentState) -> EmailAgentState:\n",
    "    \"\"\"Search knowledge base for relevant information\"\"\"\n",
    "\n",
    "    # Build search query from classification\n",
    "    classification = state.get('classification', {})\n",
    "    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n",
    "\n",
    "    try:\n",
    "        # Implement search logic here\n",
    "        search_results = [\n",
    "            \"--Search_result_1--\",\n",
    "            \"--Search_result_2--\",\n",
    "            \"--Search_result_3--\"\n",
    "        ]\n",
    "    except SearchAPIError as e:\n",
    "        # For recoverable search errors, store error and continue\n",
    "        search_results = [f\"Search temporarily unavailable: {str[e]}\"]\n",
    "\n",
    "    return {\"search_results\": search_results} # Raw search results or error\n",
    "\n",
    "def bug_tracking(state: EmailAgentState) -> EmailAgentState:\n",
    "    \"\"\"Create or update bug tracking ticket\"\"\"\n",
    "\n",
    "    # Create ticket in your bug tracking system\n",
    "    ticket_id = f\"BUG_{uuid.uuid4()}\"\n",
    "\n",
    "    return {\"ticket_id\": ticket_id}\n",
    "\n",
    "def write_response(state: EmailAgentState) -> Command[Literal[\"human_review\", \"send_reply\"]]:\n",
    "    \"Generate response using context and route based on quality\"\"\"\n",
    "\n",
    "    classification = state.get('classification', {})\n",
    "\n",
    "    # Format context from raw state data on demand\n",
    "    context_sections = []\n",
    "\n",
    "    if state.get('search_results'):\n",
    "        # Format search results for the prompt\n",
    "        formatted_docs = \"\\n\".join([f\"- {doc}\" for doc in state['search_results']])\n",
    "        context_sections.append(f\"Relevant documentation:\\n{formatted_docs}\")\n",
    "\n",
    "    if state.get('customer_history'):\n",
    "        # Format customer data for the prompt\n",
    "        context_sections.append(f\"Customer tier: {state['customer_history'].get('tier', 'standard')}\")\n",
    "\n",
    "    # Build the prompt with formatted context\n",
    "    draft_prompt = f\"\"\"\n",
    "    Draft a response to this customer email:\n",
    "    {state['email_content']}\n",
    "\n",
    "    Email intent: {classification.get('intent', 'unkown')}\n",
    "    Urgency level: {classification.get('urgency', 'medium')}\n",
    "\n",
    "    {chr(10).join(context_sections)}\n",
    "\n",
    "    Guidelines:\n",
    "    - Be professional and helpful\n",
    "    - Address their specific concern\n",
    "    - Use the provided documentation when relevant\n",
    "    - Be brief\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(draft_prompt)\n",
    "\n",
    "    # Determine if human review is needed based on urgency and intent\n",
    "    needs_review = (\n",
    "        classification.get('urgency') in ['high', 'critical'] or\n",
    "        classification.get('intent') == 'complex'\n",
    "    )\n",
    "\n",
    "    # Route to the appropriate next node\n",
    "    if needs_review:\n",
    "        goto = \"human_review\"\n",
    "        print(\"Needs approval\")\n",
    "    else:\n",
    "        goto = \"send_reply\"\n",
    "\n",
    "    return Command(\n",
    "        update = {\"draft_response\": response.content},\n",
    "        goto = goto\n",
    "    )\n",
    "\n",
    "def human_review(state: EmailAgentState) -> Command[Literal[\"send_reply\", END]]:\n",
    "    \"\"\"Pause for human review using interrupt and route based on decision\"\"\"\n",
    "\n",
    "    classification = state.get('classification', {})\n",
    "\n",
    "    # Interrupt() must come first - any code before it will re-run on resume\n",
    "    human_decision = interrupt({\n",
    "        \"email_id\": state['email_id'],\n",
    "        \"original_email\": state['email_content'],\n",
    "        \"draft_response\": state.get('draft_response', \"\"),\n",
    "        \"urgency\": classification.get('urgency'),\n",
    "        \"intent\": classification.get('intent'),\n",
    "        \"action\": \"Please review and approve/edit this response\"\n",
    "    })\n",
    "\n",
    "    # Now process the human's decision\n",
    "    if human_decision.get(\"approved\"):\n",
    "        return Command(\n",
    "            update = {\"draft_response\": human_decision.get(\"edited_response\", state['draft_response'])},\n",
    "            goto = \"send_reply\"\n",
    "        )\n",
    "    else:\n",
    "        # Rejection means human will handle directly\n",
    "        return Command(update = {}, goto = END)\n",
    "\n",
    "def send_reply(state: EmailAgentState) -> EmailAgentState:\n",
    "    \"\"\"Send the email response\"\"\"\n",
    "    # Integrate with a email service\n",
    "    print(f\"Sending reply: {state['draft_response'][:60]}...\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a65993",
   "metadata": {},
   "source": [
    "# Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "builder = StateGraph(EmailAgentState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"read_email\", read_email)\n",
    "builder.add_node(\"classify_intent\", classify_intent)\n",
    "builder.add_node(\"search_documentation\", search_documentation)\n",
    "builder.add_node(\"bug_tracking\", bug_tracking)\n",
    "builder.add_node(\"write_response\", write_response)\n",
    "builder.add_node(\"human_review\", human_review)\n",
    "builder.add_node(\"send_reply\", send_reply)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"read_email\")\n",
    "builder.add_edge(\"read_email\", \"classify_intent\")\n",
    "builder.add_edge(\"classify_intent\", \"search_documentation\")\n",
    "builder.add_edge(\"classify_intent\", \"bug_tracking\")\n",
    "builder.add_edge(\"search_documentation\", \"write_response\")\n",
    "builder.add_edge(\"bug_tracking\", \"write_response\")\n",
    "builder.add_edge(\"send_reply\", END)\n",
    "\n",
    "# Compile with checkpointer for persistence\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "memory = InMemorySaver()\n",
    "app = builder.compile(checkpointer = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5f56e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139cce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with urgent billing issue\n",
    "initial_state = {\n",
    "    \"email_content\": \"I was charged twice for my subscription! This is urgent!\",\n",
    "    \"sender_email\": \"customer@example.com\",\n",
    "    \"email_id\": \"email_123\"\n",
    "}\n",
    "\n",
    "# Run with a thread_id for persistence\n",
    "config = {\"configurable\": {\"thread_id\": \"customer_123\"}}\n",
    "result = app.invoke(initial_state, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f691a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph will pause at human_review\n",
    "print(f\"Draft ready for review: {result['draft_response'][:60]}...\\n\")\n",
    "\n",
    "# Provide human input to resume\n",
    "human_response = Command(\n",
    "    resume = {\n",
    "        \"approved\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Resume execution\n",
    "final_result = app.invoke(human_response, config)\n",
    "print(\"Email sent successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_content = [\n",
    "    \"I was charged two times for my subscription! This is urgent!\",\n",
    "    \"I was wondering if this was available in blue?\",\n",
    "    \"Can you tell me how long the sale is on?\",\n",
    "    \"The tire won't stay on the car!\",\n",
    "    \"My subscription is going to end in a few months, what is the new rate?\"\n",
    "]\n",
    "needs_approval = []\n",
    "\n",
    "for i, content in enumerate(email_content): \n",
    "\n",
    "    initial_state = {\n",
    "        \"email_content\": content,\n",
    "        \"sender_email\": \"customer@example.com\",\n",
    "        \"email_id\": f\"email_{i}\",\n",
    "    }\n",
    "    print(f\"{initial_state['email_id']}: \", end=\"\")\n",
    "\n",
    "    thread_id = uuid.uuid4()\n",
    "    config =  {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    result = app.invoke(initial_state, config)\n",
    "    if \"__interrupt__\" in result.keys():\n",
    "        result['thread_id'] = thread_id\n",
    "        needs_approval.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8084333",
   "metadata": {},
   "source": [
    ">LangSmith Trace - [Start-to-End](https://smith.langchain.com/public/3898d0d0-c934-4681-b325-7c4e1e88a826/r)  \n",
    ">LangSmith Trace - [Interrupt](https://smith.langchain.com/public/c23a3aed-cfa8-42aa-8f1e-78f58941aecd/r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e467b165-2772-44d4-80b8-1dac69e0a167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
